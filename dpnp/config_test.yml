gym_config:
    render: False
    task_dynamics_list: [0, 1, 2, 3]
    subtask_episode: 3           # the number of episode for each subtask
    subtask_episode_length: 200  # the length of each episode
    task_episode: 100            # the number of the task episode
    seed: 1000                   # seed for all environments
    dynamics_name: [             # name of all environments
        'CartPoleSwingUpEnvCm05Pm04Pl05-v0',
        'CartPoleSwingUpEnvCm05Pm04Pl07-v0',
        'CartPoleSwingUpEnvCm05Pm08Pl05-v0',
        'CartPoleSwingUpEnvCm05Pm08Pl07-v0',
    ]


# MPC controller configuration
mpc_config:
    optimizer: "Random"             # Random or CEM, # random may need to fix bugs
    Random: # TODO: warning may contain not finished modification
        env: 'swingup'           # 'stable'
        horizon: 15              # how long of the horizon to predict
        popsize: 20000            # how many random samples for mpc
        gamma: 0.99              # reward discount coefficient
        action_low: [-1]           # lower bound of the solution space
        action_high: [1]           # upper bound of the solution space
        action_dim: 1
        max_iters: 20
        num_elites: 50
        epsilon: 0.2
        alpha: 0.01
        init_mean: 0
        init_var: 10
        action_cost: False
        x_dot_cost: False
        particle: 2
    CEM:
        env: 'swingup'
        horizon: 15                # how long of the horizon to predict
        popsize: 1000               # how many random samples for mpc
        particle: 2                # number of particles to enlarge
        gamma: 1                   # reward discount coefficient
        action_low: [-1]           # lower bound of the solution space
        action_high: [1]           # upper bound of the solution space
        action_dim: 1
        max_iters: 5
        num_elites: 20
        epsilon: 0.001
        alpha: 0.1
        init_mean: 0
        init_var: 1
        action_cost: True
        x_dot_cost: False


# Model parameters
DP_config:
    stm_length: 20               # short-term memory length. Start to train when it is full
    alpha: 1.0                   # alpha initialization parameter, cartpole_stable: 0.5, cartpole_swingup: 0.5
    ada_alpha: False             # adaptively update alpha
    merge: True                  # use merge strategy in sequential_vi or not
    merge_threshold: 20.0        # merge a component when the kld is below this value
    merge_burnin: 15             # the sample number to start merge
    window_prob: 0.001           # the initial transition bias to other cluster
    self_prob: 1.0               # the initial self-transition bias

NN_config:
    model_config:
        load_model: False        # If set true, you must specify the model path, otherwise train a new model
        model_path: "./baselines/storage/example.ckpt" # the path to load the model
        state_dim: 5             # environment states
        action_dim: 1            # how many controls we need
        output_dim: 5            # output dim
        hidden_dim: 2            # hidden layer number
        hidden_size: 256         # hidden layer size
    
    training_config:
        n_epochs: 100            # how many epoches to train the dynamic model
        learning_rate: 0.0005     # learning rate
        batch_size: 64
        save_model_flag: False
        save_model_path: "./baselines/storage/exp_1.ckpt" # the path to save the model
        validation_flag: True
        validation_freq: 100      # the frequency of validation
        validation_ratio: 0.1    # ratio of validation set

SingleGP_config:
    state_dim: 5                 # dimension of the state space
    action_dim: 1                # dimension of the action space    
    lr: 0.1                      # learning rate of the gaussian process
    gp_iter: 3                   # iteration time of GP


SingleSparseGP_config:
    state_dim: 5                 # dimension of the state space
    action_dim: 1                # dimension of the action space    
    lr: 0.1                      # learning rate of the gaussian process
    gp_iter: 3                   # iteration time of GP


grbal_config:
    # Training
    valid_split_ratio: 0.1
    rolling_average_persitency: 0.99
    obs_space_dims: 5
    action_space_dims: 1
    max_path_length: 200
    n_itr: 10
    # Dynamics Model
    meta_batch_size: 10
    adapt_batch_size: 16
    hidden_nonlinearity_model: 'relu'
    learning_rate: 0.001
    inner_learning_rate: 0.001
    hidden_sizes_model: [128, 128] #(512, 512, 512),
    dynamics_model_max_epochs: 50


NP_config:
    model_config:
        load_model: False           # If set true, you must specify the model path, otherwise train a new model
        model_path: "./baselines/storage/example.ckpt" # the path to load the model
        state_dim: 4                # environment states
        action_dim: 1               # how many controls we need
        output_dim: 4               # output dim
        likelihood_method: 'gp'     # 'gp' like method or 'nn'
        likelihood_value: 'loss'    # negative 'loss' for likelihood 'll'
        sequential: False           # permute the data while training
        virtual_batch: False        # To be updated
        np_hidden_list: [1024, 1024, 1024, 1024]
        np_latent_dim: 1024


    training_config:
        n_epochs: 800            # how many epoches to train the dynamic model
        learning_rate: 0.0002     # learning rate
        batch_size: 64
        save_model_flag: False
        save_model_path: "np_save_test.ckpt" # the path to save the model
        validation_flag: False
        validation_freq: 100      # the frequency of validation
        validation_ratio: 0.1    # ratio of validation set

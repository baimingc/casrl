{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import yaml\n",
    "from utils import dumb_reward_plot\n",
    "import gym\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "sys.path.append('./envs/cartpole-envs')\n",
    "sys.path.append('./')\n",
    "import cartpole_envs\n",
    "\n",
    "from utils import plot_reward, plot_index\n",
    "from mpc.mpc_cp import MPC\n",
    "from baselines.NP_epi import NP\n",
    "\n",
    "def prepare_dynamics(gym_config):\n",
    "    dynamics_name = gym_config['dynamics_name']\n",
    "    seed = gym_config['seed']\n",
    "    dynamics_set = []\n",
    "    for i in range(len(dynamics_name)):\n",
    "        dynamics_set.append(gym.make(dynamics_name[i]))\n",
    "    task = [dynamics_set[i] for i in gym_config['task_dynamics_list']]\n",
    "    return task\n",
    "\n",
    "def load_config(config_path=\"config.yml\"):\n",
    "    if os.path.isfile(config_path):\n",
    "        f = open(config_path)\n",
    "        return yaml.load(f, Loader=yaml.FullLoader)\n",
    "    else:\n",
    "        raise Exception(\"Configuration file is not found in the path: \"+config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-10 12:16:13.946 | INFO     | __main__:<module>:9 - Using model: NP\n"
     ]
    }
   ],
   "source": [
    "# config = load_config('config/config_cpstable_np.yml')\n",
    "config = load_config('config/config_swingup_robust.yml')\n",
    "mpc_config = config['mpc_config']\n",
    "gym_config = config['gym_config']\n",
    "render = gym_config['render']\n",
    "np_config = config['NP_config']\n",
    "\n",
    "model = NP(NP_config=np_config)\n",
    "logger.info('Using model: {}', model.name)\n",
    "\n",
    "mpc_controller = MPC(mpc_config=mpc_config)\n",
    "\n",
    "# prepare task\n",
    "task = prepare_dynamics(gym_config)\n",
    "# print(gym_config)\n",
    "\n",
    "\"\"\"start DPGP-MBRL\"\"\"\n",
    "data_buffer = []\n",
    "label_list = []\n",
    "subtask_list = []\n",
    "subtask_reward = []\n",
    "subtask_succ_count = [0]\n",
    "comp_trainable = [1]\n",
    "task_reward = []\n",
    "trainable = True\n",
    "task_solved = False\n",
    "subtask_solved = [False, False, False, False]\n",
    "total_count = 0\n",
    "task_epi = 0\n",
    "log_name = None\n",
    "\n",
    "total_tasks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"NP pretrain\"\"\"\n",
    "m_p_list = [0.2, 0.8]\n",
    "l_list = [0.2, 0.8]\n",
    "pretrain_episodes = 1\n",
    "for task_idx in range(10):\n",
    "    env = task[0]\n",
    "#     m_p = m_p_list[np.random.randint(2)]\n",
    "#     l = l_list[np.random.randint(2)]\n",
    "    m_p = np.random.uniform(0.2, 0.8)\n",
    "    l = np.random.uniform(0.2, 0.8)\n",
    "    env.unwrapped.m_p = m_p\n",
    "    env.unwrapped.l = l\n",
    "    for epi in range(pretrain_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        mpc_controller.reset()\n",
    "        i = 0\n",
    "        while not done:\n",
    "            i += 1\n",
    "            action = env.action_space.sample()\n",
    "            obs_next, reward, done, _ = env.step(action)\n",
    "            model.data_process([0, obs, action, obs_next - obs])\n",
    "#             if i > 3:\n",
    "#                 model.train()\n",
    "            obs = obs_next\n",
    "    model.reset()\n",
    "    model.train()\n",
    "# torch.save(model.model.state_dict(), './misc/log/model_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = NP(NP_config=np_config)\n",
    "# model2.model.load_state_dict(torch.load( './misc/log/model_test.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.2682254192904986 pole_length:  0.7641647079072098 step:  23 acc_reward:  1.6610537930618485 violation_rate:  0.043478260869565216\n",
      "pole_mass:  0.6537160875425138 pole_length:  0.5236700044899385 step:  200 acc_reward:  42.63532544004265 violation_rate:  0.355\n",
      "pole_mass:  0.2284311950140213 pole_length:  0.7679035138193029 step:  200 acc_reward:  57.58432079876446 violation_rate:  0.21\n",
      "pole_mass:  0.6782989919885076 pole_length:  0.7149772960808691 step:  200 acc_reward:  52.82021983051892 violation_rate:  0.255\n",
      "pole_mass:  0.6490533078236105 pole_length:  0.34687072195328705 step:  29 acc_reward:  0.9288738579676027 violation_rate:  0.2413793103448276\n",
      "pole_mass:  0.37413233296570403 pole_length:  0.73065513468654 step:  200 acc_reward:  38.367752268599205 violation_rate:  0.185\n",
      "pole_mass:  0.4750200443195147 pole_length:  0.4529553489139125 step:  200 acc_reward:  24.53680210745485 violation_rate:  0.32\n",
      "pole_mass:  0.538948216843983 pole_length:  0.660247194025112 step:  200 acc_reward:  42.15395521584771 violation_rate:  0.22\n",
      "pole_mass:  0.6378013461889595 pole_length:  0.3445510528562128 step:  200 acc_reward:  63.70963200825228 violation_rate:  0.265\n",
      "pole_mass:  0.21597072880059479 pole_length:  0.6440729490723971 step:  66 acc_reward:  11.364217875873706 violation_rate:  0.2878787878787879\n",
      "pole_mass:  0.37523092402102487 pole_length:  0.2633303553013855 step:  87 acc_reward:  5.274006004119294 violation_rate:  0.3793103448275862\n",
      "pole_mass:  0.5387712343087188 pole_length:  0.4965231997861606 step:  200 acc_reward:  62.53017326154831 violation_rate:  0.18\n",
      "pole_mass:  0.510371914850709 pole_length:  0.3575349136491443 step:  200 acc_reward:  62.513627696487355 violation_rate:  0.29\n",
      "pole_mass:  0.6464302633215604 pole_length:  0.6005157674227877 step:  200 acc_reward:  48.652522182957085 violation_rate:  0.125\n",
      "pole_mass:  0.5600434438452235 pole_length:  0.6413002046308376 step:  200 acc_reward:  57.265639243520155 violation_rate:  0.23\n",
      "pole_mass:  0.6106539617585736 pole_length:  0.46699433410324787 step:  200 acc_reward:  53.663461184227835 violation_rate:  0.195\n",
      "pole_mass:  0.3510112234854023 pole_length:  0.48169203281428163 step:  200 acc_reward:  49.21046976238942 violation_rate:  0.3\n",
      "pole_mass:  0.758241657048423 pole_length:  0.42160435034728844 step:  200 acc_reward:  40.69472223687092 violation_rate:  0.015\n",
      "pole_mass:  0.651606808130816 pole_length:  0.7835521687929499 step:  200 acc_reward:  30.784629426041903 violation_rate:  0.225\n",
      "pole_mass:  0.7866177814896325 pole_length:  0.2934006133329845 step:  200 acc_reward:  24.01201374077618 violation_rate:  0.135\n",
      "pole_mass:  0.547172342547641 pole_length:  0.2503648582091407 step:  99 acc_reward:  17.698312358851144 violation_rate:  0.3434343434343434\n",
      "pole_mass:  0.2574081878255616 pole_length:  0.7751816422532682 step:  200 acc_reward:  42.10264454661409 violation_rate:  0.0\n",
      "pole_mass:  0.3972132552629884 pole_length:  0.7288461464270404 step:  200 acc_reward:  55.03081565760564 violation_rate:  0.125\n",
      "pole_mass:  0.5621253168825724 pole_length:  0.26770624271058474 step:  200 acc_reward:  28.70277352449084 violation_rate:  0.145\n",
      "pole_mass:  0.31335931864216343 pole_length:  0.5049264972410485 step:  200 acc_reward:  116.73451423933135 violation_rate:  0.15\n",
      "pole_mass:  0.5524396838587795 pole_length:  0.46418123711316267 step:  200 acc_reward:  83.44883960838445 violation_rate:  0.31\n",
      "pole_mass:  0.7649460750025106 pole_length:  0.687148555462012 step:  200 acc_reward:  48.87143836938274 violation_rate:  0.245\n",
      "pole_mass:  0.33822789441694096 pole_length:  0.7606156050529129 step:  200 acc_reward:  45.034645918987735 violation_rate:  0.04\n",
      "pole_mass:  0.5388187073110187 pole_length:  0.5588845101606763 step:  200 acc_reward:  96.82417150874204 violation_rate:  0.01\n",
      "pole_mass:  0.694213224461576 pole_length:  0.7005854586136846 step:  200 acc_reward:  36.755231662558856 violation_rate:  0.055\n",
      "pole_mass:  0.4766839128442898 pole_length:  0.25303475178945334 step:  200 acc_reward:  22.93376409044847 violation_rate:  0.205\n",
      "pole_mass:  0.535301238807474 pole_length:  0.777201640929083 step:  200 acc_reward:  99.82063137051053 violation_rate:  0.0\n",
      "pole_mass:  0.6862385329096952 pole_length:  0.31786892806717004 step:  200 acc_reward:  75.80021455529787 violation_rate:  0.095\n",
      "pole_mass:  0.25981415733183055 pole_length:  0.3336199104680285 step:  200 acc_reward:  51.566570957567606 violation_rate:  0.115\n",
      "pole_mass:  0.7708608159543926 pole_length:  0.5555294128676209 step:  200 acc_reward:  110.69523977655629 violation_rate:  0.01\n",
      "pole_mass:  0.2377365241211966 pole_length:  0.35978717404924915 step:  200 acc_reward:  128.13961349541916 violation_rate:  0.005\n",
      "pole_mass:  0.41571121068679256 pole_length:  0.6981954374517704 step:  200 acc_reward:  98.20810242125523 violation_rate:  0.335\n",
      "pole_mass:  0.3650766796108739 pole_length:  0.7588003763848146 step:  200 acc_reward:  81.50322204316551 violation_rate:  0.055\n",
      "pole_mass:  0.7167871264170251 pole_length:  0.31946299966801195 step:  200 acc_reward:  45.172152525058586 violation_rate:  0.055\n",
      "pole_mass:  0.7229811346125044 pole_length:  0.2742397385446216 step:  200 acc_reward:  22.58629608029974 violation_rate:  0.16\n",
      "pole_mass:  0.2867435973356511 pole_length:  0.49644750338233395 step:  200 acc_reward:  89.02963621352649 violation_rate:  0.26\n",
      "pole_mass:  0.7449574876431277 pole_length:  0.6934765251913869 step:  200 acc_reward:  105.55248195617136 violation_rate:  0.0\n",
      "pole_mass:  0.6862299681562207 pole_length:  0.33376272976945437 step:  200 acc_reward:  105.20317562332471 violation_rate:  0.08\n",
      "pole_mass:  0.3015554737844627 pole_length:  0.6026752325287155 step:  200 acc_reward:  70.01478280715094 violation_rate:  0.04\n",
      "pole_mass:  0.4647286267785559 pole_length:  0.4352721554893678 step:  200 acc_reward:  65.13572954084131 violation_rate:  0.005\n",
      "pole_mass:  0.3972097220767451 pole_length:  0.6639913943896507 step:  200 acc_reward:  28.883594323692286 violation_rate:  0.1\n",
      "pole_mass:  0.22968571175003008 pole_length:  0.2732981567864793 step:  200 acc_reward:  40.772077302639055 violation_rate:  0.06\n",
      "pole_mass:  0.7019052136749317 pole_length:  0.6089291423774144 step:  200 acc_reward:  96.69073917623581 violation_rate:  0.07\n",
      "pole_mass:  0.5381181895957459 pole_length:  0.577348357624602 step:  200 acc_reward:  80.13072174152997 violation_rate:  0.0\n",
      "pole_mass:  0.7119887567332042 pole_length:  0.7082182040070335 step:  200 acc_reward:  158.2700463000566 violation_rate:  0.0\n",
      "pole_mass:  0.5286951513335673 pole_length:  0.3246654822462679 step:  200 acc_reward:  64.18414001847822 violation_rate:  0.0\n",
      "pole_mass:  0.41110637208962464 pole_length:  0.7772671698527296 step:  200 acc_reward:  172.55323302466974 violation_rate:  0.06\n",
      "pole_mass:  0.43638948715514425 pole_length:  0.7188202896107558 step:  200 acc_reward:  99.95536607714399 violation_rate:  0.015\n",
      "pole_mass:  0.2614180024773258 pole_length:  0.7690433199827391 step:  200 acc_reward:  58.15138686984807 violation_rate:  0.425\n",
      "pole_mass:  0.5120310691236778 pole_length:  0.5940039258982539 step:  200 acc_reward:  49.602628509040635 violation_rate:  0.14\n",
      "pole_mass:  0.7376506639493967 pole_length:  0.4242156199778707 step:  200 acc_reward:  69.56685457314656 violation_rate:  0.0\n",
      "pole_mass:  0.6602420903459194 pole_length:  0.7945243052000814 step:  200 acc_reward:  65.42529119530589 violation_rate:  0.025\n",
      "pole_mass:  0.3781902969142885 pole_length:  0.44485464457359686 step:  200 acc_reward:  115.54157130217405 violation_rate:  0.035\n",
      "pole_mass:  0.659680481924027 pole_length:  0.7470581256465467 step:  200 acc_reward:  103.2996172179138 violation_rate:  0.145\n",
      "pole_mass:  0.7118088053376381 pole_length:  0.7341638168327984 step:  200 acc_reward:  124.2980369394181 violation_rate:  0.0\n",
      "pole_mass:  0.33254235376440033 pole_length:  0.34316877225218834 step:  200 acc_reward:  120.87234961935134 violation_rate:  0.09\n",
      "pole_mass:  0.3295417844474775 pole_length:  0.4922998105891978 step:  200 acc_reward:  86.23646425922686 violation_rate:  0.0\n",
      "pole_mass:  0.5938268308519841 pole_length:  0.7131049899989079 step:  200 acc_reward:  34.431867611788476 violation_rate:  0.175\n",
      "pole_mass:  0.3655807517240725 pole_length:  0.4182210918373341 step:  200 acc_reward:  74.77891108248376 violation_rate:  0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.6802054784903289 pole_length:  0.22140637972527985 step:  200 acc_reward:  33.942604181483176 violation_rate:  0.05\n",
      "pole_mass:  0.24558387193196612 pole_length:  0.46184738700388994 step:  200 acc_reward:  150.5160968953595 violation_rate:  0.215\n",
      "pole_mass:  0.4211325333635755 pole_length:  0.4071982996891522 step:  200 acc_reward:  46.19562494926389 violation_rate:  0.0\n",
      "pole_mass:  0.4829184118754236 pole_length:  0.7320819562758691 step:  200 acc_reward:  107.51539568971091 violation_rate:  0.015\n",
      "pole_mass:  0.6594079217953484 pole_length:  0.41919501169798035 step:  200 acc_reward:  78.1709756690576 violation_rate:  0.0\n",
      "pole_mass:  0.2804910887489263 pole_length:  0.4898683741842365 step:  200 acc_reward:  159.96963773096252 violation_rate:  0.11\n",
      "pole_mass:  0.6417247727399011 pole_length:  0.5988153935733902 step:  200 acc_reward:  84.07872984475182 violation_rate:  0.0\n",
      "pole_mass:  0.5848481535843549 pole_length:  0.7061656926652515 step:  200 acc_reward:  41.67433505183124 violation_rate:  0.23\n",
      "pole_mass:  0.3140166411074118 pole_length:  0.33922029410202725 step:  200 acc_reward:  65.20318822420191 violation_rate:  0.025\n",
      "pole_mass:  0.6071804303837318 pole_length:  0.3078844915251062 step:  200 acc_reward:  51.34224082503567 violation_rate:  0.0\n",
      "pole_mass:  0.4474885250023081 pole_length:  0.476281615694486 step:  200 acc_reward:  104.11213352889497 violation_rate:  0.015\n",
      "pole_mass:  0.38656476662820327 pole_length:  0.5709502055222256 step:  200 acc_reward:  158.26052685172723 violation_rate:  0.055\n",
      "pole_mass:  0.7278022741516892 pole_length:  0.43058899614532764 step:  200 acc_reward:  84.95447777100239 violation_rate:  0.0\n",
      "pole_mass:  0.24944894416145777 pole_length:  0.2192450955820524 step:  53 acc_reward:  10.105801399431812 violation_rate:  0.07547169811320754\n",
      "pole_mass:  0.22325194542605464 pole_length:  0.7562346641954347 step:  200 acc_reward:  73.88992400899257 violation_rate:  0.045\n",
      "pole_mass:  0.5255557049472452 pole_length:  0.5875478412477511 step:  200 acc_reward:  115.92548230992708 violation_rate:  0.225\n",
      "pole_mass:  0.5761793062566831 pole_length:  0.6086896760165594 step:  200 acc_reward:  89.80687326866922 violation_rate:  0.01\n",
      "pole_mass:  0.21747167336748427 pole_length:  0.2739474932806117 step:  200 acc_reward:  66.20082484263708 violation_rate:  0.055\n",
      "pole_mass:  0.3193274490220895 pole_length:  0.3347457376810186 step:  200 acc_reward:  131.17572007149488 violation_rate:  0.085\n",
      "pole_mass:  0.22428389674034713 pole_length:  0.43922291515969153 step:  200 acc_reward:  98.0097646774174 violation_rate:  0.01\n",
      "pole_mass:  0.458000141223606 pole_length:  0.5039821485936282 step:  200 acc_reward:  35.47179013897966 violation_rate:  0.16\n",
      "pole_mass:  0.5185870629304896 pole_length:  0.6936849907109397 step:  200 acc_reward:  80.3365994617169 violation_rate:  0.15\n",
      "pole_mass:  0.5006892762362843 pole_length:  0.39663399491939455 step:  200 acc_reward:  84.27321677074495 violation_rate:  0.0\n",
      "pole_mass:  0.389190838849098 pole_length:  0.5051752559562268 step:  200 acc_reward:  75.605333534086 violation_rate:  0.0\n",
      "pole_mass:  0.3502911644320627 pole_length:  0.7531893096766691 step:  200 acc_reward:  117.84923588489292 violation_rate:  0.54\n",
      "pole_mass:  0.7215720689275353 pole_length:  0.381946190993115 step:  200 acc_reward:  62.65160621118563 violation_rate:  0.02\n",
      "pole_mass:  0.47216966338908584 pole_length:  0.23161429057260474 step:  176 acc_reward:  13.001108770109123 violation_rate:  0.03409090909090909\n",
      "pole_mass:  0.5640797024886894 pole_length:  0.5529102902908389 step:  200 acc_reward:  108.49215559905376 violation_rate:  0.19\n",
      "pole_mass:  0.7345687609729155 pole_length:  0.6107122530020914 step:  200 acc_reward:  162.15336072175003 violation_rate:  0.0\n",
      "pole_mass:  0.4943378205158992 pole_length:  0.7395438309889353 step:  200 acc_reward:  82.30749392534891 violation_rate:  0.09\n",
      "pole_mass:  0.2258990585055776 pole_length:  0.5327351543454415 step:  200 acc_reward:  73.30117054948005 violation_rate:  0.01\n",
      "pole_mass:  0.3878900192303467 pole_length:  0.33179379085499106 step:  200 acc_reward:  85.64969480252638 violation_rate:  0.05\n",
      "pole_mass:  0.5237623641927753 pole_length:  0.4040115308162917 step:  200 acc_reward:  150.40636029082683 violation_rate:  0.31\n",
      "pole_mass:  0.7601004887366205 pole_length:  0.2909043674778613 step:  200 acc_reward:  78.3759265964607 violation_rate:  0.0\n",
      "pole_mass:  0.7981803625467339 pole_length:  0.49308245881565665 step:  200 acc_reward:  54.10080097354701 violation_rate:  0.0\n",
      "pole_mass:  0.7566047491078092 pole_length:  0.21208962746963686 step:  13 acc_reward:  1.4445745904591005 violation_rate:  0.15384615384615385\n",
      "pole_mass:  0.42291045393027615 pole_length:  0.6492341552121991 step:  200 acc_reward:  75.0950985420134 violation_rate:  0.02\n",
      "pole_mass:  0.36512068920777935 pole_length:  0.799658517885834 step:  200 acc_reward:  159.03842681804176 violation_rate:  0.2\n",
      "pole_mass:  0.6936736348759428 pole_length:  0.5553987514751696 step:  200 acc_reward:  135.48050461247826 violation_rate:  0.015\n",
      "pole_mass:  0.21813238080253627 pole_length:  0.282198139719127 step:  200 acc_reward:  105.64539865917403 violation_rate:  0.065\n",
      "pole_mass:  0.49112336963796593 pole_length:  0.2642906697212438 step:  200 acc_reward:  45.92713521983497 violation_rate:  0.0\n",
      "pole_mass:  0.2957216312483746 pole_length:  0.6431141849899338 step:  200 acc_reward:  172.12126674802437 violation_rate:  0.155\n",
      "pole_mass:  0.20368581143703746 pole_length:  0.6227979804598445 step:  200 acc_reward:  102.95932602992947 violation_rate:  0.045\n",
      "pole_mass:  0.2774571827311587 pole_length:  0.2617787837608434 step:  200 acc_reward:  87.06720714604371 violation_rate:  0.06\n",
      "pole_mass:  0.6481366110902418 pole_length:  0.20932915197657184 step:  22 acc_reward:  2.678919035800801 violation_rate:  0.09090909090909091\n",
      "pole_mass:  0.5701405038862677 pole_length:  0.3331921381637357 step:  200 acc_reward:  85.62372487992639 violation_rate:  0.005\n",
      "pole_mass:  0.5952959262307222 pole_length:  0.4998340604755864 step:  200 acc_reward:  142.94451493289236 violation_rate:  0.15\n",
      "pole_mass:  0.743244384885164 pole_length:  0.6438123965926923 step:  200 acc_reward:  102.15198199235954 violation_rate:  0.0\n",
      "pole_mass:  0.562207595901837 pole_length:  0.5194229033064159 step:  200 acc_reward:  176.17486858577874 violation_rate:  0.11\n",
      "pole_mass:  0.6480899876985335 pole_length:  0.5263693032105894 step:  200 acc_reward:  128.8290844073167 violation_rate:  0.005\n",
      "pole_mass:  0.2629226316702939 pole_length:  0.6675237619843314 step:  200 acc_reward:  112.42803842125777 violation_rate:  0.05\n",
      "pole_mass:  0.4422234123737289 pole_length:  0.40139691145393663 step:  200 acc_reward:  98.71188115200546 violation_rate:  0.01\n",
      "pole_mass:  0.7543358610689237 pole_length:  0.5839396867877182 step:  200 acc_reward:  81.22331006752037 violation_rate:  0.02\n",
      "pole_mass:  0.502169863029952 pole_length:  0.4861297932564482 step:  200 acc_reward:  117.32298725635025 violation_rate:  0.155\n",
      "pole_mass:  0.7911383646743206 pole_length:  0.7916858291921567 step:  200 acc_reward:  98.78019783617968 violation_rate:  0.0\n",
      "pole_mass:  0.5955000854206514 pole_length:  0.4776207055650021 step:  200 acc_reward:  144.73574831031593 violation_rate:  0.16\n",
      "pole_mass:  0.3225969925094512 pole_length:  0.3259791875677406 step:  200 acc_reward:  136.7594847539181 violation_rate:  0.22\n",
      "pole_mass:  0.4941992346133347 pole_length:  0.6197046349810957 step:  200 acc_reward:  114.59835317954523 violation_rate:  0.37\n",
      "pole_mass:  0.35103628536097414 pole_length:  0.2606009919169246 step:  200 acc_reward:  75.62047474963285 violation_rate:  0.095\n",
      "pole_mass:  0.5881884560481832 pole_length:  0.2866947295753588 step:  200 acc_reward:  86.00723519460861 violation_rate:  0.015\n",
      "pole_mass:  0.6511140594533205 pole_length:  0.48232331212814167 step:  200 acc_reward:  67.53225282610298 violation_rate:  0.01\n",
      "pole_mass:  0.7987998046372597 pole_length:  0.7188038683771003 step:  200 acc_reward:  94.79783940132796 violation_rate:  0.18\n",
      "pole_mass:  0.7323749022063524 pole_length:  0.618922711844232 step:  200 acc_reward:  168.56801999092937 violation_rate:  0.025\n",
      "pole_mass:  0.724927785742105 pole_length:  0.5640146462424538 step:  200 acc_reward:  171.97521345255933 violation_rate:  0.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.7474302260735208 pole_length:  0.44473655245733523 step:  200 acc_reward:  148.4300366759846 violation_rate:  0.125\n",
      "pole_mass:  0.7000939640436392 pole_length:  0.6989913868207087 step:  200 acc_reward:  40.777164547205004 violation_rate:  0.19\n",
      "pole_mass:  0.5413670496472931 pole_length:  0.35325914618395704 step:  200 acc_reward:  88.2517403452875 violation_rate:  0.04\n",
      "pole_mass:  0.4798207189394212 pole_length:  0.47824296421907747 step:  200 acc_reward:  87.6000483398073 violation_rate:  0.01\n",
      "pole_mass:  0.2508457105397381 pole_length:  0.278113960503952 step:  200 acc_reward:  88.86590994822316 violation_rate:  0.015\n",
      "pole_mass:  0.20385666304830402 pole_length:  0.21682103244647932 step:  63 acc_reward:  7.064291551693475 violation_rate:  0.015873015873015872\n",
      "pole_mass:  0.282279657548258 pole_length:  0.28012198999836724 step:  200 acc_reward:  73.35170228623063 violation_rate:  0.04\n",
      "pole_mass:  0.38619408378191167 pole_length:  0.7317927658249497 step:  200 acc_reward:  84.84136386030258 violation_rate:  0.24\n",
      "pole_mass:  0.5557391953396897 pole_length:  0.6142424346854398 step:  200 acc_reward:  174.64085912854443 violation_rate:  0.11\n",
      "pole_mass:  0.22117310900379095 pole_length:  0.4360201929445391 step:  200 acc_reward:  91.28970993841733 violation_rate:  0.015\n",
      "pole_mass:  0.6802212069256044 pole_length:  0.20953769854464366 step:  53 acc_reward:  6.72250611609578 violation_rate:  0.03773584905660377\n",
      "pole_mass:  0.39794578901075617 pole_length:  0.41927298726042184 step:  200 acc_reward:  180.99556297243143 violation_rate:  0.17\n",
      "pole_mass:  0.3466998313503338 pole_length:  0.7587564510847178 step:  200 acc_reward:  66.2211331527717 violation_rate:  0.235\n",
      "pole_mass:  0.29965227913216896 pole_length:  0.7081476295438747 step:  200 acc_reward:  157.37359084554336 violation_rate:  0.175\n",
      "pole_mass:  0.35794224240493766 pole_length:  0.6923187564586751 step:  200 acc_reward:  157.0028194444634 violation_rate:  0.065\n",
      "pole_mass:  0.2775195922260712 pole_length:  0.3989125167356379 step:  200 acc_reward:  71.51143505827828 violation_rate:  0.0\n",
      "pole_mass:  0.5079303042148747 pole_length:  0.2115748393871798 step:  174 acc_reward:  7.762866123698498 violation_rate:  0.034482758620689655\n",
      "pole_mass:  0.37080816900376024 pole_length:  0.3575358593681581 step:  200 acc_reward:  70.89905548838166 violation_rate:  0.015\n",
      "pole_mass:  0.4837037586770737 pole_length:  0.400971334168784 step:  200 acc_reward:  135.21331109330137 violation_rate:  0.305\n",
      "pole_mass:  0.7861021508502783 pole_length:  0.25428636768748525 step:  200 acc_reward:  39.05532291234321 violation_rate:  0.005\n",
      "pole_mass:  0.6521082901157951 pole_length:  0.3658356291706924 step:  200 acc_reward:  44.50230665601435 violation_rate:  0.0\n",
      "pole_mass:  0.7830789732138983 pole_length:  0.4376495787647886 step:  200 acc_reward:  97.25573810510137 violation_rate:  0.175\n",
      "pole_mass:  0.6337784163209185 pole_length:  0.44856761236246817 step:  200 acc_reward:  108.18610066434796 violation_rate:  0.24\n",
      "pole_mass:  0.7521197149934291 pole_length:  0.2501445860157312 step:  200 acc_reward:  53.450133744343646 violation_rate:  0.015\n",
      "pole_mass:  0.5698020501090573 pole_length:  0.46310059917161117 step:  200 acc_reward:  52.58292301427975 violation_rate:  0.0\n",
      "pole_mass:  0.7414237648488124 pole_length:  0.36123974659935026 step:  200 acc_reward:  113.01671257870704 violation_rate:  0.05\n",
      "pole_mass:  0.7623165920207466 pole_length:  0.3119698815862672 step:  200 acc_reward:  77.17935967819868 violation_rate:  0.035\n",
      "pole_mass:  0.48601593111082525 pole_length:  0.668884147254469 step:  200 acc_reward:  167.38753528869313 violation_rate:  0.0\n",
      "pole_mass:  0.42738949518041963 pole_length:  0.2196057721582347 step:  67 acc_reward:  10.655257619521098 violation_rate:  0.08955223880597014\n",
      "pole_mass:  0.594882513832325 pole_length:  0.7109988420656739 step:  200 acc_reward:  150.47116790575717 violation_rate:  0.035\n",
      "pole_mass:  0.41143213789608096 pole_length:  0.59220244787975 step:  200 acc_reward:  145.11984956699337 violation_rate:  0.41\n",
      "pole_mass:  0.5950012527212606 pole_length:  0.6647859990754013 step:  200 acc_reward:  127.51506627382815 violation_rate:  0.045\n",
      "pole_mass:  0.44872583521432374 pole_length:  0.2555706963441423 step:  200 acc_reward:  43.08891145602591 violation_rate:  0.035\n",
      "pole_mass:  0.42547242658106826 pole_length:  0.7128864960103649 step:  200 acc_reward:  125.64212544637908 violation_rate:  0.19\n",
      "pole_mass:  0.7577409396726105 pole_length:  0.4696535710394573 step:  200 acc_reward:  96.06601826317761 violation_rate:  0.0\n",
      "pole_mass:  0.3260693211556601 pole_length:  0.6799211541893684 step:  200 acc_reward:  149.7772164817114 violation_rate:  0.065\n",
      "pole_mass:  0.4374974047926922 pole_length:  0.2794739934589827 step:  200 acc_reward:  79.7855637392779 violation_rate:  0.025\n",
      "pole_mass:  0.33618223999178143 pole_length:  0.5263045248939694 step:  200 acc_reward:  132.90661442787817 violation_rate:  0.18\n",
      "pole_mass:  0.46575086948495525 pole_length:  0.30120497727457035 step:  200 acc_reward:  99.53530718731584 violation_rate:  0.145\n",
      "pole_mass:  0.6084230599007596 pole_length:  0.27204379477395974 step:  200 acc_reward:  47.90927578253692 violation_rate:  0.07\n",
      "pole_mass:  0.47143265584459054 pole_length:  0.603151266001976 step:  200 acc_reward:  175.35576607305657 violation_rate:  0.105\n",
      "pole_mass:  0.56222189972368 pole_length:  0.7545425381703368 step:  200 acc_reward:  121.61706102905102 violation_rate:  0.065\n",
      "pole_mass:  0.4007577209873079 pole_length:  0.5582961260366284 step:  200 acc_reward:  172.50322129588994 violation_rate:  0.11\n",
      "pole_mass:  0.3529823776970654 pole_length:  0.260079369537093 step:  200 acc_reward:  46.22315339187912 violation_rate:  0.025\n",
      "pole_mass:  0.2703426283500397 pole_length:  0.4370013193194425 step:  200 acc_reward:  154.66660029441567 violation_rate:  0.095\n",
      "pole_mass:  0.3804631682049465 pole_length:  0.5240520086158408 step:  200 acc_reward:  144.10257766924238 violation_rate:  0.105\n",
      "pole_mass:  0.4214492811603201 pole_length:  0.591016431353802 step:  200 acc_reward:  63.735822827762206 violation_rate:  0.425\n",
      "pole_mass:  0.5134274548010207 pole_length:  0.7303443453182792 step:  200 acc_reward:  124.523035574257 violation_rate:  0.23\n",
      "pole_mass:  0.2092108282785925 pole_length:  0.36479514677716096 step:  200 acc_reward:  96.61848288591841 violation_rate:  0.01\n",
      "pole_mass:  0.5325835516743662 pole_length:  0.5754178341801391 step:  200 acc_reward:  158.00598349230066 violation_rate:  0.19\n",
      "pole_mass:  0.4600296399723317 pole_length:  0.20272206650197758 step:  27 acc_reward:  2.198403472606896 violation_rate:  0.07407407407407407\n",
      "pole_mass:  0.6036770745490925 pole_length:  0.7481646683115659 step:  200 acc_reward:  45.44532364922959 violation_rate:  0.185\n",
      "pole_mass:  0.4654949359969156 pole_length:  0.3397716773732109 step:  200 acc_reward:  25.824932268935854 violation_rate:  0.16\n",
      "pole_mass:  0.6951818782574095 pole_length:  0.761209460436278 step:  200 acc_reward:  101.78421579097657 violation_rate:  0.21\n",
      "pole_mass:  0.23700865702312918 pole_length:  0.37813997521285203 step:  200 acc_reward:  90.65223599406201 violation_rate:  0.01\n",
      "pole_mass:  0.47539512761841024 pole_length:  0.2085521408225308 step:  99 acc_reward:  21.748393517881055 violation_rate:  0.050505050505050504\n",
      "pole_mass:  0.39564565886248426 pole_length:  0.794861187524617 step:  200 acc_reward:  169.34140453429166 violation_rate:  0.19\n",
      "pole_mass:  0.5789234430904984 pole_length:  0.4362066237936804 step:  200 acc_reward:  167.7987876963299 violation_rate:  0.2\n",
      "pole_mass:  0.21203727746701903 pole_length:  0.3996238425902954 step:  200 acc_reward:  161.49026073544564 violation_rate:  0.15\n",
      "pole_mass:  0.38554473625019636 pole_length:  0.6178440715712781 step:  200 acc_reward:  93.95354117275394 violation_rate:  0.115\n",
      "pole_mass:  0.5935311833222376 pole_length:  0.7625955994946747 step:  200 acc_reward:  77.52284679028513 violation_rate:  0.05\n",
      "pole_mass:  0.5522821859872893 pole_length:  0.3321778669745704 step:  200 acc_reward:  121.80251038138977 violation_rate:  0.235\n",
      "pole_mass:  0.2103260208212734 pole_length:  0.55964421077465 step:  200 acc_reward:  171.95687422833254 violation_rate:  0.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.30508389898524424 pole_length:  0.7045367833208667 step:  200 acc_reward:  128.90567153934458 violation_rate:  0.025\n",
      "pole_mass:  0.43692434996799173 pole_length:  0.36135925030521193 step:  200 acc_reward:  134.14939201393707 violation_rate:  0.255\n",
      "pole_mass:  0.5738523527603065 pole_length:  0.3089002851580625 step:  200 acc_reward:  105.83847697570978 violation_rate:  0.07\n",
      "pole_mass:  0.45311449269489473 pole_length:  0.78418445133733 step:  200 acc_reward:  142.7674911588145 violation_rate:  0.13\n",
      "pole_mass:  0.46908550985939573 pole_length:  0.4641925277000066 step:  200 acc_reward:  47.279441960280515 violation_rate:  0.0\n",
      "pole_mass:  0.20494751062682887 pole_length:  0.7877513487398655 step:  200 acc_reward:  164.0435163928172 violation_rate:  0.045\n",
      "pole_mass:  0.20321292168086663 pole_length:  0.5348023492533192 step:  200 acc_reward:  161.59921853946474 violation_rate:  0.37\n",
      "pole_mass:  0.4520940350389533 pole_length:  0.37269967789390546 step:  200 acc_reward:  133.70575643235813 violation_rate:  0.085\n",
      "pole_mass:  0.4077578207559441 pole_length:  0.7530284164978802 step:  200 acc_reward:  143.48446677163255 violation_rate:  0.03\n",
      "pole_mass:  0.7037595274386215 pole_length:  0.4714533398788697 step:  200 acc_reward:  103.9173995383105 violation_rate:  0.18\n",
      "pole_mass:  0.3467185393785307 pole_length:  0.3979650543382238 step:  200 acc_reward:  124.88054556627723 violation_rate:  0.05\n",
      "pole_mass:  0.34944871223336293 pole_length:  0.4594739874412396 step:  200 acc_reward:  168.51929815770774 violation_rate:  0.155\n",
      "pole_mass:  0.5138515375187309 pole_length:  0.45516950452390603 step:  200 acc_reward:  158.70517633374243 violation_rate:  0.065\n",
      "pole_mass:  0.48454856496718224 pole_length:  0.6266594557291852 step:  200 acc_reward:  144.88135836899917 violation_rate:  0.0\n",
      "pole_mass:  0.46842873373592286 pole_length:  0.31649061173653276 step:  200 acc_reward:  88.39666976159889 violation_rate:  0.03\n",
      "pole_mass:  0.7383990761131023 pole_length:  0.7815514650259785 step:  200 acc_reward:  83.83407976386746 violation_rate:  0.36\n",
      "pole_mass:  0.26591909376742795 pole_length:  0.4126571681430978 step:  200 acc_reward:  176.95489245286112 violation_rate:  0.245\n",
      "pole_mass:  0.7715233756610478 pole_length:  0.7012137405682397 step:  200 acc_reward:  107.71811475239136 violation_rate:  0.02\n",
      "pole_mass:  0.561450162336308 pole_length:  0.3219334201121483 step:  200 acc_reward:  96.99825925147583 violation_rate:  0.0\n",
      "pole_mass:  0.3257404828115845 pole_length:  0.43077266123435287 step:  200 acc_reward:  179.1106325354077 violation_rate:  0.105\n",
      "pole_mass:  0.4063444004488616 pole_length:  0.75466056634315 step:  200 acc_reward:  174.52936271668932 violation_rate:  0.0\n",
      "pole_mass:  0.436914664914728 pole_length:  0.4389194075391689 step:  200 acc_reward:  153.56686774500326 violation_rate:  0.155\n",
      "pole_mass:  0.34639805512715993 pole_length:  0.20468393366725815 step:  68 acc_reward:  17.220803690220595 violation_rate:  0.029411764705882353\n",
      "pole_mass:  0.4342776984544122 pole_length:  0.36453699650266436 step:  59 acc_reward:  3.788575867378763 violation_rate:  0.11864406779661017\n",
      "pole_mass:  0.5792209185439815 pole_length:  0.48245117791541975 step:  200 acc_reward:  92.97263207466978 violation_rate:  0.38\n",
      "pole_mass:  0.21077987538888293 pole_length:  0.5645496580677587 step:  35 acc_reward:  5.366837950458643 violation_rate:  0.02857142857142857\n",
      "pole_mass:  0.5993665649914477 pole_length:  0.22201389689631715 step:  46 acc_reward:  0.3374138400006644 violation_rate:  0.043478260869565216\n",
      "pole_mass:  0.5870516060954961 pole_length:  0.4291427425413678 step:  200 acc_reward:  47.0111114103648 violation_rate:  0.0\n",
      "pole_mass:  0.5085066755795843 pole_length:  0.5232637760657279 step:  200 acc_reward:  105.33603504518247 violation_rate:  0.0\n",
      "pole_mass:  0.5661268934489402 pole_length:  0.3042127989275315 step:  200 acc_reward:  70.29395392731456 violation_rate:  0.225\n",
      "pole_mass:  0.30242699728861167 pole_length:  0.24141035535957095 step:  39 acc_reward:  5.28887982339101 violation_rate:  0.23076923076923078\n",
      "pole_mass:  0.33882199047619943 pole_length:  0.28042068495065087 step:  200 acc_reward:  53.969566493958865 violation_rate:  0.07\n",
      "pole_mass:  0.2713939538410961 pole_length:  0.4772427869258255 step:  200 acc_reward:  151.48128055359746 violation_rate:  0.1\n",
      "pole_mass:  0.7161118702195362 pole_length:  0.7927522888741354 step:  200 acc_reward:  167.96595060975125 violation_rate:  0.055\n",
      "pole_mass:  0.7154056909730886 pole_length:  0.6770005227617544 step:  200 acc_reward:  61.09629149667244 violation_rate:  0.205\n",
      "pole_mass:  0.2555969838650667 pole_length:  0.3307068570513454 step:  200 acc_reward:  17.640571557518072 violation_rate:  0.0\n",
      "pole_mass:  0.6478569024924556 pole_length:  0.4724735960748339 step:  200 acc_reward:  23.21565813605409 violation_rate:  0.25\n",
      "pole_mass:  0.3194977166362721 pole_length:  0.42937413154331305 step:  200 acc_reward:  68.19176161054062 violation_rate:  0.32\n",
      "pole_mass:  0.5389832847914131 pole_length:  0.20759739038881483 step:  27 acc_reward:  4.7871895611827595 violation_rate:  0.037037037037037035\n",
      "pole_mass:  0.6300004127970049 pole_length:  0.47563668140643506 step:  200 acc_reward:  100.26284732741426 violation_rate:  0.085\n",
      "pole_mass:  0.5312608979849051 pole_length:  0.3620081851399319 step:  200 acc_reward:  172.18057174133708 violation_rate:  0.235\n",
      "pole_mass:  0.7654052127075679 pole_length:  0.3717303023491319 step:  200 acc_reward:  93.54982554989947 violation_rate:  0.075\n",
      "pole_mass:  0.2922010693158064 pole_length:  0.3338987138626929 step:  200 acc_reward:  98.14279748608173 violation_rate:  0.185\n",
      "pole_mass:  0.5350385613487967 pole_length:  0.36467408180359867 step:  200 acc_reward:  139.46261704898666 violation_rate:  0.24\n",
      "pole_mass:  0.7743209999951233 pole_length:  0.37691524360496464 step:  200 acc_reward:  115.9367334498134 violation_rate:  0.215\n",
      "pole_mass:  0.24241277627594962 pole_length:  0.46866754986895914 step:  200 acc_reward:  91.54482736687751 violation_rate:  0.0\n",
      "pole_mass:  0.6514660818315674 pole_length:  0.20512194420945162 step:  16 acc_reward:  1.2827257778188517 violation_rate:  0.125\n",
      "pole_mass:  0.23596035628969253 pole_length:  0.6029897284358929 step:  200 acc_reward:  78.54966826969618 violation_rate:  0.055\n",
      "pole_mass:  0.44251962407383816 pole_length:  0.39476427207691867 step:  200 acc_reward:  174.22911425721495 violation_rate:  0.205\n",
      "pole_mass:  0.7633622996660803 pole_length:  0.3648680714686029 step:  200 acc_reward:  123.05449311318004 violation_rate:  0.165\n",
      "pole_mass:  0.6230389266319494 pole_length:  0.6758930919929798 step:  200 acc_reward:  90.25138899332507 violation_rate:  0.0\n",
      "pole_mass:  0.7484200207484661 pole_length:  0.5753494563161062 step:  200 acc_reward:  36.22411359217069 violation_rate:  0.28\n",
      "pole_mass:  0.3587576329056098 pole_length:  0.5088929777180848 step:  200 acc_reward:  122.84721601425855 violation_rate:  0.2\n",
      "pole_mass:  0.46981927095589865 pole_length:  0.5796686399860658 step:  200 acc_reward:  105.55813158881273 violation_rate:  0.045\n",
      "pole_mass:  0.23299327608418624 pole_length:  0.7271544444245832 step:  200 acc_reward:  96.05050380243688 violation_rate:  0.0\n",
      "pole_mass:  0.38680271507371317 pole_length:  0.44259828193282463 step:  200 acc_reward:  62.08086493785941 violation_rate:  0.135\n",
      "pole_mass:  0.36984574696881156 pole_length:  0.7317367885036512 step:  200 acc_reward:  129.13035496735824 violation_rate:  0.005\n",
      "pole_mass:  0.49708099792392735 pole_length:  0.5156750302326416 step:  200 acc_reward:  173.76253336281871 violation_rate:  0.1\n",
      "pole_mass:  0.3308132751676243 pole_length:  0.5177615146529937 step:  200 acc_reward:  178.1345209327928 violation_rate:  0.19\n",
      "pole_mass:  0.7637398661370585 pole_length:  0.5483143146704366 step:  200 acc_reward:  124.42847847653344 violation_rate:  0.0\n",
      "pole_mass:  0.3682791510096183 pole_length:  0.269204704145952 step:  200 acc_reward:  104.3188104565929 violation_rate:  0.005\n",
      "pole_mass:  0.7197893131870823 pole_length:  0.44828902102779267 step:  200 acc_reward:  148.10641982705624 violation_rate:  0.06\n",
      "pole_mass:  0.7633672416200254 pole_length:  0.2858252328695859 step:  200 acc_reward:  134.4416421101438 violation_rate:  0.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.6029155283238954 pole_length:  0.7722967875266495 step:  200 acc_reward:  61.967077600045926 violation_rate:  0.0\n",
      "pole_mass:  0.34221429174467993 pole_length:  0.5613684071325417 step:  200 acc_reward:  162.36126590099474 violation_rate:  0.02\n",
      "pole_mass:  0.4973523131281714 pole_length:  0.45662349100219674 step:  200 acc_reward:  151.63553773190273 violation_rate:  0.22\n",
      "pole_mass:  0.21967017431971225 pole_length:  0.2782494907811556 step:  200 acc_reward:  95.12253065125175 violation_rate:  0.0\n",
      "pole_mass:  0.24671144556804753 pole_length:  0.5004253108568328 step:  200 acc_reward:  128.48445567339058 violation_rate:  0.23\n",
      "pole_mass:  0.47487682648679225 pole_length:  0.43973887570311443 step:  200 acc_reward:  74.71456233674343 violation_rate:  0.01\n",
      "pole_mass:  0.5371754940848892 pole_length:  0.6639859089110451 step:  200 acc_reward:  160.31458324347358 violation_rate:  0.115\n",
      "pole_mass:  0.43744110781960993 pole_length:  0.7269899831785911 step:  200 acc_reward:  117.29508191923459 violation_rate:  0.065\n",
      "pole_mass:  0.249816372582861 pole_length:  0.21492210114820554 step:  22 acc_reward:  4.35902531241229 violation_rate:  0.045454545454545456\n",
      "pole_mass:  0.5364280356683935 pole_length:  0.609078793947204 step:  200 acc_reward:  105.4992769957549 violation_rate:  0.035\n",
      "pole_mass:  0.5062157545096106 pole_length:  0.7412837459745141 step:  200 acc_reward:  176.8865207069624 violation_rate:  0.0\n",
      "pole_mass:  0.3287622917627421 pole_length:  0.20737792650604706 step:  200 acc_reward:  45.88108698900675 violation_rate:  0.01\n",
      "pole_mass:  0.7386950340093679 pole_length:  0.290597540305656 step:  200 acc_reward:  85.38022354950967 violation_rate:  0.065\n",
      "pole_mass:  0.7275489089032028 pole_length:  0.6163136636650925 step:  200 acc_reward:  49.75179609166546 violation_rate:  0.135\n",
      "pole_mass:  0.5554856518467125 pole_length:  0.23362156279178908 step:  200 acc_reward:  40.348275880767744 violation_rate:  0.005\n",
      "pole_mass:  0.3788131683810341 pole_length:  0.6015381435876059 step:  200 acc_reward:  181.67009690020194 violation_rate:  0.065\n",
      "pole_mass:  0.6304827786203357 pole_length:  0.7225714518379076 step:  200 acc_reward:  146.047819450337 violation_rate:  0.22\n",
      "pole_mass:  0.20359988251680225 pole_length:  0.6293444928581031 step:  200 acc_reward:  140.51113482707748 violation_rate:  0.07\n",
      "pole_mass:  0.5529446337296515 pole_length:  0.22760485774257921 step:  187 acc_reward:  51.91678211337971 violation_rate:  0.0748663101604278\n",
      "pole_mass:  0.25841093757476086 pole_length:  0.2179070310113152 step:  153 acc_reward:  33.54082369028361 violation_rate:  0.0196078431372549\n",
      "pole_mass:  0.7218531434556255 pole_length:  0.6976715017391238 step:  200 acc_reward:  94.20748059536736 violation_rate:  0.0\n",
      "pole_mass:  0.6014119492462333 pole_length:  0.3116273466883692 step:  200 acc_reward:  116.6755208120265 violation_rate:  0.205\n",
      "pole_mass:  0.7279044377522781 pole_length:  0.7653582417964075 step:  200 acc_reward:  81.51234406570279 violation_rate:  0.035\n",
      "pole_mass:  0.6268285492618837 pole_length:  0.6329426045265241 step:  200 acc_reward:  58.8160433770146 violation_rate:  0.005\n",
      "pole_mass:  0.28583355467651705 pole_length:  0.38079884772715145 step:  200 acc_reward:  132.16278259882333 violation_rate:  0.14\n",
      "pole_mass:  0.5868274757915528 pole_length:  0.6844023618694679 step:  200 acc_reward:  100.89921879228345 violation_rate:  0.015\n",
      "pole_mass:  0.3868143861572105 pole_length:  0.6898861363499433 step:  200 acc_reward:  85.80722334655981 violation_rate:  0.0\n",
      "pole_mass:  0.31050445150829864 pole_length:  0.6214906461898098 step:  200 acc_reward:  104.86490143267191 violation_rate:  0.005\n",
      "pole_mass:  0.6044456803711996 pole_length:  0.22207681185332706 step:  200 acc_reward:  47.16467132780807 violation_rate:  0.025\n",
      "pole_mass:  0.7241115632028103 pole_length:  0.5975696162268069 step:  200 acc_reward:  137.27794182430415 violation_rate:  0.0\n",
      "pole_mass:  0.7071038551182871 pole_length:  0.7422296698874546 step:  200 acc_reward:  55.047305238333614 violation_rate:  0.0\n",
      "pole_mass:  0.5562424826807119 pole_length:  0.4094886989104881 step:  200 acc_reward:  118.77256441136561 violation_rate:  0.335\n",
      "pole_mass:  0.4360804796723183 pole_length:  0.5997115956092618 step:  200 acc_reward:  136.0503791815071 violation_rate:  0.01\n",
      "pole_mass:  0.44814968193284765 pole_length:  0.7117159531194601 step:  200 acc_reward:  89.55462958092849 violation_rate:  0.0\n",
      "pole_mass:  0.20233664654230601 pole_length:  0.2757621170391207 step:  200 acc_reward:  68.06639885622884 violation_rate:  0.08\n",
      "pole_mass:  0.47769509507992347 pole_length:  0.6209666422110824 step:  200 acc_reward:  103.955778478004 violation_rate:  0.005\n",
      "pole_mass:  0.7880680573511618 pole_length:  0.7465292917632644 step:  200 acc_reward:  104.02520209938807 violation_rate:  0.0\n",
      "pole_mass:  0.4957295737769509 pole_length:  0.518624156899593 step:  200 acc_reward:  144.65672944255417 violation_rate:  0.075\n",
      "pole_mass:  0.56775803207098 pole_length:  0.3590743601324128 step:  200 acc_reward:  131.1215007877421 violation_rate:  0.195\n",
      "pole_mass:  0.5639721032068402 pole_length:  0.5758115367512555 step:  200 acc_reward:  156.93590967251694 violation_rate:  0.0\n",
      "pole_mass:  0.4018585297128485 pole_length:  0.7953720736638523 step:  200 acc_reward:  164.78975760024514 violation_rate:  0.015\n",
      "pole_mass:  0.42108144322544827 pole_length:  0.6758263396368596 step:  200 acc_reward:  92.35216861126105 violation_rate:  0.0\n",
      "pole_mass:  0.24265725911163905 pole_length:  0.5558389048285867 step:  200 acc_reward:  117.73868431621133 violation_rate:  0.08\n",
      "pole_mass:  0.494456534249432 pole_length:  0.2166510488746773 step:  46 acc_reward:  5.298793478547919 violation_rate:  0.08695652173913043\n",
      "pole_mass:  0.36683487359485123 pole_length:  0.5534202254540477 step:  200 acc_reward:  71.45125584132674 violation_rate:  0.0\n",
      "pole_mass:  0.35883977917983856 pole_length:  0.3245763815651863 step:  200 acc_reward:  80.52180615052062 violation_rate:  0.015\n"
     ]
    }
   ],
   "source": [
    "# log_name == None\n",
    "\"\"\"testing the model with MPC while training \"\"\"\n",
    "test_episode = 1\n",
    "test_epoch = 300\n",
    "log = []\n",
    "m_p_list = [0.3, 0.7]\n",
    "l_list = [0.3, 0.7]\n",
    "\n",
    "for ep in range(test_epoch):\n",
    "    for task_idx in range(1):\n",
    "        task_steps = 0\n",
    "        env = task[0]\n",
    "#         m_p = m_p_list[np.random.randint(2)]\n",
    "#         l = l_list[np.random.randint(2)]\n",
    "        m_p = np.random.uniform(0.2, 0.8)\n",
    "        l = np.random.uniform(0.2, 0.8)\n",
    "        env.unwrapped.m_p = m_p\n",
    "        env.unwrapped.l = l\n",
    "        for epi in range(test_episode):\n",
    "            acc_reward = 0\n",
    "            obs = env.reset()\n",
    "            O, A, R, acc_reward, done, V = [], [], [], 0, False, []\n",
    "            mpc_controller.reset()\n",
    "            i = 0\n",
    "            while not done:\n",
    "                i+= 1\n",
    "                env_copy = prepare_dynamics(gym_config)[0]\n",
    "                env_copy.unwrapped.m_p = m_p\n",
    "                env_copy.unwrapped.l = l\n",
    "                env_copy.reset()\n",
    "                if task_steps > 0:\n",
    "                    action = np.array([mpc_controller.act(task=env_copy, model=model, state=obs, ground_truth=True)])\n",
    "                else:\n",
    "                    action = np.array([0.0])\n",
    "                obs_next, reward, done, violation = env.step(action)\n",
    "                task_steps += 1\n",
    "                A.append(action)\n",
    "                O.append(obs_next)\n",
    "                R.append(reward)\n",
    "                V.append(violation)\n",
    "\n",
    "                model.data_process([0, obs, action, obs_next - obs])\n",
    "#                 if task_steps > 2:\n",
    "#                     model.train()\n",
    "                obs = obs_next\n",
    "                acc_reward += reward\n",
    "#             print('task: ', task_idx,'step: ', i, 'acc_reward: ', acc_reward, 'violation_rate: ', sum(V)/len(V))\n",
    "            print('pole_mass: ', m_p, 'pole_length: ', l, 'step: ', i, 'acc_reward: ', acc_reward, 'violation_rate: ', sum(V)/len(V))\n",
    "            env.close()\n",
    "\n",
    "            if done:\n",
    "                samples = {\n",
    "                    \"obs\": np.array(O),\n",
    "                    \"actions\": np.array(A),\n",
    "                    \"rewards\": np.array(R),\n",
    "                    \"reward_sum\": acc_reward,\n",
    "                    \"violation_rate\": sum(V)/len(V)\n",
    "                }\n",
    "                log.append(samples)\n",
    "                if log_name is None:\n",
    "                    log_name = datetime.datetime.now()\n",
    "                path = './misc/log/np_adaptation' + log_name.strftime(\"%d-%H-%M\") + '.npy'\n",
    "#                 print(path)\n",
    "                np.save(path, log, allow_pickle=True)\n",
    "                dumb_reward_plot(path)\n",
    "        model.reset()\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), './misc/log/robust_model_latent-' + log_name.strftime(\"%d-%H-%M\") + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./misc/log/np_adaptation10-09-22.npy\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.3 pole_length:  0.7 step:  200 acc_reward:  155.37174407349997 violation_rate:  0.035\n",
      "pole_mass:  0.3 pole_length:  0.3 step:  200 acc_reward:  152.98799105235113 violation_rate:  0.09\n",
      "pole_mass:  0.7 pole_length:  0.3 step:  200 acc_reward:  111.36387528293744 violation_rate:  0.0\n",
      "pole_mass:  0.3 pole_length:  0.7 step:  200 acc_reward:  96.15357172916583 violation_rate:  0.285\n",
      "pole_mass:  0.3 pole_length:  0.7 step:  200 acc_reward:  155.69317472118897 violation_rate:  0.095\n",
      "pole_mass:  0.7 pole_length:  0.7 step:  200 acc_reward:  158.11743615910416 violation_rate:  0.035\n",
      "pole_mass:  0.3 pole_length:  0.7 step:  200 acc_reward:  137.99629515002746 violation_rate:  0.235\n",
      "pole_mass:  0.7 pole_length:  0.3 step:  200 acc_reward:  97.34392621617955 violation_rate:  0.0\n",
      "pole_mass:  0.3 pole_length:  0.7 step:  200 acc_reward:  123.25752336064429 violation_rate:  0.22\n",
      "pole_mass:  0.7 pole_length:  0.7 step:  200 acc_reward:  173.97169360055324 violation_rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "config = load_config('config/config_swingup_robust.yml')\n",
    "mpc_config = config['mpc_config']\n",
    "mpc_controller = MPC(mpc_config=mpc_config)\n",
    "\"\"\"testing the model with MPC while training \"\"\"\n",
    "test_episode = 1\n",
    "test_epoch = 10\n",
    "log = []\n",
    "m_p_list = [0.3, 0.7]\n",
    "l_list = [0.3, 0.7]\n",
    "\n",
    "for ep in range(test_epoch):\n",
    "    for task_idx in range(1):\n",
    "        task_steps = 0\n",
    "        env = task[0]\n",
    "        m_p = m_p_list[np.random.randint(2)]\n",
    "        l = l_list[np.random.randint(2)]\n",
    "        env.unwrapped.m_p = m_p\n",
    "        env.unwrapped.l = l\n",
    "        for epi in range(test_episode):\n",
    "            acc_reward = 0\n",
    "            obs = env.reset()\n",
    "            O, A, R, acc_reward, done, V = [], [], [], 0, False, []\n",
    "            mpc_controller.reset()\n",
    "            i = 0\n",
    "            while not done:\n",
    "                i+= 1\n",
    "                env_copy = prepare_dynamics(gym_config)[0]\n",
    "                env_copy.unwrapped.m_p = m_p\n",
    "                env_copy.unwrapped.l = l\n",
    "                env_copy.reset()\n",
    "                if task_steps > 0:\n",
    "                    action = np.array([mpc_controller.act(task=env_copy, model=model, state=obs, ground_truth=True)])\n",
    "                else:\n",
    "                    action = np.array([0.0])\n",
    "                obs_next, reward, done, violation = env.step(action)\n",
    "                task_steps += 1\n",
    "                A.append(action)\n",
    "                O.append(obs_next)\n",
    "                R.append(reward)\n",
    "                V.append(violation)\n",
    "\n",
    "                model.data_process([0, obs, action, obs_next - obs])\n",
    "                obs = obs_next\n",
    "                acc_reward += reward\n",
    "#             print('task: ', task_idx,'step: ', i, 'acc_reward: ', acc_reward, 'violation_rate: ', sum(V)/len(V))\n",
    "            print('pole_mass: ', m_p, 'pole_length: ', l, 'step: ', i, 'acc_reward: ', acc_reward, 'violation_rate: ', sum(V)/len(V))\n",
    "            env.close()\n",
    "\n",
    "            if done:\n",
    "                samples = {\n",
    "                    \"obs\": np.array(O),\n",
    "                    \"actions\": np.array(A),\n",
    "                    \"rewards\": np.array(R),\n",
    "                    \"reward_sum\": acc_reward,\n",
    "                    \"violation_rate\": sum(V)/len(V)\n",
    "                }\n",
    "                log.append(samples)\n",
    "#                 if log_name is None:\n",
    "#                     log_name = datetime.datetime.now()\n",
    "#                 path = './misc/log/np_adaptation' + log_name.strftime(\"%d-%H-%M\") + '.npy'\n",
    "#                 np.save(path, log, allow_pickle=True)\n",
    "#                 dumb_reward_plot(path)\n",
    "            \n",
    "        model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pole_mass:  0.25 pole_length:  0.25 step:  200 acc_reward:  21.051632777875387 violation_rate:  0.09\n",
      "pole_mass:  0.4 pole_length:  0.25 step:  200 acc_reward:  36.31640757246856 violation_rate:  0.08\n",
      "pole_mass:  0.6 pole_length:  0.25 step:  200 acc_reward:  35.74430377746248 violation_rate:  0.13\n",
      "pole_mass:  0.75 pole_length:  0.25 step:  200 acc_reward:  51.05605037326064 violation_rate:  0.065\n",
      "pole_mass:  0.25 pole_length:  0.4 step:  200 acc_reward:  155.9412494983333 violation_rate:  0.015\n",
      "pole_mass:  0.4 pole_length:  0.4 step:  200 acc_reward:  87.03557698739318 violation_rate:  0.015\n",
      "pole_mass:  0.6 pole_length:  0.4 step:  200 acc_reward:  129.75732806755954 violation_rate:  0.075\n",
      "pole_mass:  0.75 pole_length:  0.4 step:  200 acc_reward:  163.10355475050773 violation_rate:  0.025\n",
      "pole_mass:  0.25 pole_length:  0.6 step:  200 acc_reward:  173.775165547779 violation_rate:  0.01\n",
      "pole_mass:  0.4 pole_length:  0.6 step:  200 acc_reward:  173.2729320840893 violation_rate:  0.005\n",
      "pole_mass:  0.6 pole_length:  0.6 step:  200 acc_reward:  145.66749230481707 violation_rate:  0.02\n",
      "pole_mass:  0.75 pole_length:  0.6 step:  200 acc_reward:  45.98920178310945 violation_rate:  0.015\n",
      "pole_mass:  0.25 pole_length:  0.75 step:  200 acc_reward:  66.20703414727144 violation_rate:  0.065\n",
      "pole_mass:  0.4 pole_length:  0.75 step:  200 acc_reward:  64.91604277157246 violation_rate:  0.275\n",
      "pole_mass:  0.6 pole_length:  0.75 step:  200 acc_reward:  41.9333070371439 violation_rate:  0.145\n",
      "pole_mass:  0.75 pole_length:  0.75 step:  200 acc_reward:  58.17927121799694 violation_rate:  0.225\n"
     ]
    }
   ],
   "source": [
    "# only_prior_model\n",
    "test_episode = 1\n",
    "test_epoch = 10\n",
    "log = []\n",
    "m_p_list = [0.25, 0.4, 0.6, 0.75]\n",
    "l_list = [0.25, 0.4, 0.6, 0.75]\n",
    "for l in l_list:\n",
    "    for m_p in m_p_list:\n",
    "#     for l in l_list:\n",
    "        task_steps = 0\n",
    "        env = task[0]\n",
    "#         m_p = m_p_list[np.random.randint(2)]\n",
    "#         l = l_list[np.random.randint(2)]\n",
    "        env.unwrapped.m_p = m_p\n",
    "        env.unwrapped.l = l\n",
    "        for epi in range(test_episode):\n",
    "            acc_reward = 0\n",
    "            obs = env.reset()\n",
    "            O, A, R, acc_reward, done, V = [], [], [], 0, False, []\n",
    "            mpc_controller.reset()\n",
    "            i = 0\n",
    "            while not done:\n",
    "                i+= 1\n",
    "                env_copy = prepare_dynamics(gym_config)[0]\n",
    "                env_copy.unwrapped.m_p = m_p\n",
    "                env_copy.unwrapped.l = l\n",
    "                env_copy.reset()\n",
    "                if task_steps > 0:\n",
    "                    action = np.array([mpc_controller.act(task=env_copy, model=model, state=obs, ground_truth=True)])\n",
    "                else:\n",
    "                    action = np.array([0.0])\n",
    "                obs_next, reward, done, violation = env.step(action)\n",
    "                task_steps += 1\n",
    "                A.append(action)\n",
    "                O.append(obs_next)\n",
    "                R.append(reward)\n",
    "                V.append(violation)\n",
    "\n",
    "                model.data_process([0, obs, action, obs_next - obs])\n",
    "                obs = obs_next\n",
    "                acc_reward += reward\n",
    "#             print('task: ', task_idx,'step: ', i, 'acc_reward: ', acc_reward, 'violation_rate: ', sum(V)/len(V))\n",
    "            print('pole_mass: ', m_p, 'pole_length: ', l, 'step: ', i, 'acc_reward: ', acc_reward, 'violation_rate: ', sum(V)/len(V))\n",
    "            env.close()\n",
    "\n",
    "            if done:\n",
    "                samples = {\n",
    "                    \"obs\": np.array(O),\n",
    "                    \"actions\": np.array(A),\n",
    "                    \"rewards\": np.array(R),\n",
    "                    \"reward_sum\": acc_reward,\n",
    "                    \"violation_rate\": sum(V)/len(V)\n",
    "                }\n",
    "                log.append(samples)\n",
    "#                 if log_name is None:\n",
    "#                     log_name = datetime.datetime.now()\n",
    "#                 path = './misc/log/np_adaptation' + log_name.strftime(\"%d-%H-%M\") + '.npy'\n",
    "#                 np.save(path, log, allow_pickle=True)\n",
    "#                 dumb_reward_plot(path)\n",
    "            \n",
    "        model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "a= [0, 1, 2]\n",
    "s = random.sample(a, 2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([4, 5, 6], [1, 2, 3])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "a = deque(maxlen=100)\n",
    "xx = [1,2,3]\n",
    "yy = [4,5,6]\n",
    "a.append((xx,yy))\n",
    "a.append((yy,xx))\n",
    "s = random.sample(a, k=1)\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

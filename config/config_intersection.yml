gym_config:
    render: False
    task_dynamics_list: [0, 1, 2]
    subtask_episode: 3           # the number of episode for each subtask
    subtask_episode_length: None  # the length of each episode
    task_episode: 100            # the number of the task episode
    seed: 1000                   # seed for all environments
    dynamics_name: [             # name of all environments
        'intersection-v21',
        'intersection-v20',
        'intersection-v12',
    ]

# MPC controller configuration
mpc_config:
    optimizer: "CEM"             # Random or CEM
    CEM:
        horizon: 20                # how long of the horizon to predict, 10
        popsize: 200               # how many random samples for mpc
        particle: 1                # number of particles to enlarge
        gamma: 1                   # reward discount coefficient
        action_low: [-1]           # lower bound of the solution space
        action_high: [1]           # upper bound of the solution space
        action_dim: 2
        max_iters: 5
        num_elites: 20
        epsilon: 0.001
        alpha: 0.1
        init_mean: 0
        init_var: 1
        action_cost: False


# Model parameters
DPGP_config:
    mode: "FullState"       # "FullState", "VelocityField"

    FullState:
        alpha: 0.1                   # alpha initialization parameter, cartpole_stable: 0.5, cartpole_swingup: 0.5
        ada_alpha: False             # adaptively update alpha
        state_dim: 12                 # dimension of the state space
        action_dim: 2                # dimension of the action space
        lr: 0.1                      # learning rate of the gaussian process
        gp_iter: 10                   # iteration time of GP
        merge: True                  # use merge strategy in sequential_vi or not
        merge_threshold: 60.0        # merge a component when the kld is below this value
        merge_burnin: 15             # the sample number to start merge
        model_type: 'sample'         # choose the model type [exact/sparse/sample]
        max_inducing_point: 1300      # Used in [sparse/sample]. the data number after do a sparse operation
        trigger_induce: 1500          # Used in [sparse/sample]. when n is larger than this value, do a sparse operation
        sample_number: 100           # Used in [sample]. number of MC samples to find the highest lower bound
        window_prob: 0.001           # the initial transition bias to other cluster
        self_prob: 1.0               # the initial self-transition bias
        param: [                     # GP initilize and constraint parameters
            0.001,    # noise_covar initilize
            0.0001,   # noise_covar constraint
            0.0,      # constant initilize
            0.5,      # outputscale initilize
            1.0,      # lengthscale initilize
        ]

    VelocityField:
        alpha: 0.1                   # alpha initialization parameter, cartpole_stable: 0.5, cartpole_swingup: 0.5
        ada_alpha: False             # adaptively update alpha
        state_dim: 2                 # dimension of the state space
        action_dim: 2                # dimension of the action space
        lr: 0.1                      # learning rate of the gaussian process
        gp_iter: 10                   # iteration time of GP
        merge: True                  # use merge strategy in sequential_vi or not
        merge_threshold: 60.0        # merge a component when the kld is below this value
        merge_burnin: 15             # the sample number to start merge
        model_type: 'sample'         # choose the model type [exact/sparse/sample]
        max_inducing_point: 1300      # Used in [sparse/sample]. the data number after do a sparse operation
        trigger_induce: 1500          # Used in [sparse/sample]. when n is larger than this value, do a sparse operation
        sample_number: 100           # Used in [sample]. number of MC samples to find the highest lower bound
        window_prob: 0.001           # the initial transition bias to other cluster
        self_prob: 1.0               # the initial self-transition bias
        param: [                     # GP initilize and constraint parameters
            0.001,    # noise_covar initilize
            0.0001,   # noise_covar constraint
            0.0,      # constant initilize
            0.5,      # outputscale initilize
            1.0,      # lengthscale initilize
        ]

SingleGP_config: # use exact inducing points
    state_dim: 12                 # dimension of the state space
    action_dim: 2                # dimension of the action space
    lr: 0.1                      # learning rate of the gaussian process
    gp_iter: 10                  # iteration time of GP
    max_inducing_point: 400     # the data number after do a sparse operation
    trigger_induce: 600         # when n is larger than this value, do a sparse operation
    sample_number: 100           # number of MC samples to find the highest lower bound
    param: [                     # GP initilize and constraint parameters
        0.0001,    # noise_covar initilize
        0.00001,   # noise_covar constraint
        0.0,      # constant initilize
        0.4,      # outputscale initilize
        1.0,      # lengthscale initilize
    ]


SingleSparseGP_config: # use pseudo-inducing points
    state_dim: 12                 # dimension of the state space
    action_dim: 2                # dimension of the action space
    lr: 0.1                      # learning rate of the gaussian process
    gp_iter: 10                  # iteration time of GP
    max_inducing_point: 500     # the data number after do a sparse operation
    param: [                     # GP initilize and constraint parameters
        0.0001,    # noise_covar initilize
        0.00001,   # noise_covar constraint
        0.0,      # constant initilize
        0.4,      # outputscale initilize
        1.0,      # lengthscale initilize
    ]


NN_config:
    model_config:
        load_model: False        # If set true, you must specify the model path, otherwise train a new model
        model_path: "./baselines/storage/example.ckpt" # the path to load the model
        state_dim: 12             # environment states
        action_dim: 2            # how many controls we need
        output_dim: 12            # output dim
        hidden_dim: 2            # hidden layer number
        hidden_size: 256         # hidden layer size

    training_config:
        n_epochs: 100            # how many epoches to train the dynamic model
        learning_rate: 0.008     # learning rate
        batch_size: 128
        save_model_flag: False
        save_model_path: "./baselines/storage/exp_1.ckpt" # the path to save the model
        validation_flag: False
        validation_freq: 10      # the frequency of validation
        validation_ratio: 0.2    # ratio of validation set
        exp_number: 1            # experiment number

    dataset_config:
        load_flag: False
        load_path: "./baselines/storage/data_exp_1.pkl"
        n_max_steps: 1000        # maximum steps per episode
        n_random_episodes: 800   # how many random episodes' data to fit the initial dynamic model
        testset_split: 0.2       # testset's portion in the random dataset, the rest portion is the training set
        n_mpc_episodes: 4        # how many episodes data sampled with the MPC controller
        mpc_dataset_split: 0.5   # mpc dataset's portion in the training set
        min_train_samples: 6000
        n_mpc_itrs: 100          # the number to perform reinforce iteration
        save_flag: False         # set True if you want to save all the dataset
        save_path: "./baselines/storage/data_exp_1.pkl"


grbal_config:
    # Training
    valid_split_ratio: 0.1
    rolling_average_persitency: 0.99
    obs_space_dims: 5
    action_space_dims: 1
    max_path_length: 200
    n_itr: 10

    # Dynamics Model
    meta_batch_size: 10
    adapt_batch_size: 16
    hidden_nonlinearity_model: 'relu'
    learning_rate: 0.001
    inner_learning_rate: 0.001
    hidden_sizes_model: [128, 128] #(512, 512, 512),
    dynamics_model_max_epochs: 50
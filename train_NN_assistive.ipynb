{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import yaml\n",
    "from utils import dumb_reward_plot\n",
    "import gym\n",
    "import assistive_gym\n",
    "\n",
    "# sys.path.append('./envs/cartpole-envs')\n",
    "# sys.path.append('./')\n",
    "# import cartpole_envs\n",
    "#import highway_env\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from utils import plot_reward, plot_index\n",
    "from mpc.mpc_ar import MPC\n",
    "from baselines.NN import NN\n",
    "\n",
    "\n",
    "def load_config(config_path=\"config.yml\"):\n",
    "    if os.path.isfile(config_path):\n",
    "        f = open(config_path)\n",
    "        return yaml.load(f, Loader=yaml.FullLoader)\n",
    "    else:\n",
    "        raise Exception(\"Configuration file is not found in the path: \"+config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-06 16:28:48.853 | INFO     | __main__:<module>:12 - Using model: NN\n",
      "Using TensorFlow backend.\n",
      "/home/baiming/anaconda3/envs/robustnp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/baiming/anaconda3/envs/robustnp/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/baiming/anaconda3/envs/robustnp/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/baiming/anaconda3/envs/robustnp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = load_config('config/config_assistant_robot_NN.yml')\n",
    "nn_config = config['NN_config']\n",
    "mpc_config = config['mpc_config']\n",
    "gym_config = config['gym_config']\n",
    "render = gym_config['render']\n",
    "\n",
    "# initialize the mixture model\n",
    "# model = DPGPMM(dpgp_config=dpgp_config)\n",
    "# model = SingleSparseGP(sparse_gp_config=sparse_gp_config)\n",
    "# model = SingleGP(gp_config=gp_config)\n",
    "model = NN(NN_config=nn_config)\n",
    "logger.info('Using model: {}', model.name)\n",
    "\n",
    "# initial MPC controller\n",
    "mpc_controller = MPC(mpc_config=mpc_config)\n",
    "\n",
    "# prepare task\n",
    "# the task is solved, if each dynamic is solved\n",
    "env = gym.make(\"FeedingJaco-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.370362254732754e-06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"NN pretrain\"\"\"\n",
    "pretrain_episodes = 5\n",
    "    # data collection\n",
    "for epi in range(pretrain_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    mpc_controller.reset()\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "#             print(obs_next-obs)\n",
    "        model.data_process([0, obs, action, obs_next - obs])\n",
    "        obs = obs_next\n",
    "\n",
    "model.validation_flag = True\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_reward:  -154.2186206412283 success_food 0 spilled_food 0 distance 1.0251738437770324\n",
      "acc_reward:  -61.43187157201522 success_food 0 spilled_food 0 distance 0.2084717424480841\n",
      "acc_reward:  -125.51141801444815 success_food 0 spilled_food 0 distance 0.6416243593547212\n",
      "acc_reward:  -76.04800702047527 success_food 0 spilled_food 8 distance 0.15849836175824053\n",
      "acc_reward:  -52.21722246975764 success_food 0 spilled_food 0 distance 0.2066000246915539\n",
      "acc_reward:  -67.21847716091862 success_food 0 spilled_food 0 distance 0.32310550988096215\n",
      "acc_reward:  -108.16467581595161 success_food 0 spilled_food 0 distance 0.40426748372192983\n",
      "acc_reward:  120.44007421244572 success_food 8 spilled_food 0 distance 0.08518135366400885\n",
      "acc_reward:  -64.81158983547289 success_food 0 spilled_food 0 distance 0.18198915803197163\n",
      "acc_reward:  -55.948098239505164 success_food 0 spilled_food 0 distance 0.16726692201518517\n",
      "acc_reward:  -54.502419000587274 success_food 0 spilled_food 0 distance 0.1349684089691924\n",
      "acc_reward:  106.92854687953388 success_food 8 spilled_food 0 distance 0.08489402110393682\n",
      "acc_reward:  -85.2468122239973 success_food 0 spilled_food 0 distance 0.361400427131219\n",
      "acc_reward:  -57.754371125571254 success_food 0 spilled_food 0 distance 0.06429320281431543\n",
      "acc_reward:  -185.28784734088123 success_food 0 spilled_food 5 distance 1.0277021745127293\n",
      "acc_reward:  -109.13150391742674 success_food 0 spilled_food 0 distance 0.43188788522431215\n",
      "acc_reward:  -92.7816778913225 success_food 0 spilled_food 0 distance 0.47504939217640285\n",
      "acc_reward:  -151.70763778630175 success_food 0 spilled_food 0 distance 0.7644257578193961\n",
      "acc_reward:  -80.52550793700802 success_food 0 spilled_food 1 distance 0.11290895704745349\n",
      "acc_reward:  -81.31894443389862 success_food 0 spilled_food 0 distance 0.27590000384777497\n",
      "acc_reward:  -105.58937492713007 success_food 0 spilled_food 0 distance 0.446440698358607\n",
      "acc_reward:  -94.50279907910559 success_food 0 spilled_food 0 distance 0.40531003985999614\n",
      "acc_reward:  -126.92574801311287 success_food 0 spilled_food 0 distance 0.6422267404719234\n",
      "acc_reward:  -116.36600750324487 success_food 0 spilled_food 0 distance 0.5396660436666111\n",
      "acc_reward:  -141.27399741317285 success_food 0 spilled_food 0 distance 0.7292837281432097\n",
      "acc_reward:  -113.22063690760571 success_food 0 spilled_food 0 distance 0.5922256419126538\n",
      "acc_reward:  -113.42457106219116 success_food 0 spilled_food 0 distance 0.5397143227439082\n",
      "acc_reward:  -85.27387745195264 success_food 0 spilled_food 0 distance 0.4028101828018779\n",
      "acc_reward:  -79.64748126890493 success_food 0 spilled_food 0 distance 0.3240313459699085\n",
      "acc_reward:  -136.61819978104404 success_food 0 spilled_food 0 distance 0.6822369074147816\n",
      "acc_reward:  -125.40833402917295 success_food 0 spilled_food 0 distance 0.6104501714703228\n",
      "acc_reward:  -131.03318189552206 success_food 0 spilled_food 0 distance 0.7660990364330894\n",
      "acc_reward:  -104.68994523865175 success_food 0 spilled_food 0 distance 0.5028399947259006\n",
      "acc_reward:  -99.85147878548688 success_food 0 spilled_food 0 distance 0.4908171981911811\n",
      "acc_reward:  -67.83110394743139 success_food 0 spilled_food 0 distance 0.22471304024222283\n",
      "acc_reward:  -92.47916241592566 success_food 0 spilled_food 0 distance 0.3228915150870067\n",
      "acc_reward:  -102.90205028742278 success_food 0 spilled_food 0 distance 0.4681549895769496\n",
      "acc_reward:  -94.21969714936168 success_food 0 spilled_food 0 distance 0.3139596316312871\n",
      "acc_reward:  -94.23644974134 success_food 0 spilled_food 0 distance 0.39115199691825675\n",
      "acc_reward:  -87.42506197282219 success_food 0 spilled_food 0 distance 0.4042728218955704\n",
      "acc_reward:  -73.51967440558205 success_food 0 spilled_food 0 distance 0.3018488684974692\n",
      "acc_reward:  -52.22638560297614 success_food 0 spilled_food 0 distance 0.06304604362308412\n",
      "acc_reward:  -99.86819816830895 success_food 0 spilled_food 0 distance 0.4267854359219181\n",
      "acc_reward:  -56.66076897356895 success_food 0 spilled_food 0 distance 0.18848049097431344\n",
      "acc_reward:  -92.21929368033342 success_food 0 spilled_food 0 distance 0.45798050762217457\n",
      "acc_reward:  -99.12643013825141 success_food 0 spilled_food 0 distance 0.37431162085018255\n",
      "acc_reward:  -44.889985953279755 success_food 0 spilled_food 0 distance 0.09148426121421382\n",
      "acc_reward:  -98.84232008868072 success_food 0 spilled_food 0 distance 0.4986591103942875\n",
      "acc_reward:  -93.83126431695165 success_food 0 spilled_food 0 distance 0.4483380125682939\n",
      "acc_reward:  -92.86272629487885 success_food 0 spilled_food 0 distance 0.42136085250790917\n",
      "acc_reward:  -63.676343486688495 success_food 0 spilled_food 1 distance 0.18681047392656067\n",
      "acc_reward:  -96.56138538949254 success_food 0 spilled_food 0 distance 0.40517631214593036\n",
      "acc_reward:  -105.97326840929432 success_food 0 spilled_food 0 distance 0.46914127520033155\n",
      "acc_reward:  -59.080001460958016 success_food 0 spilled_food 0 distance 0.20851261517238165\n",
      "acc_reward:  -125.62557829970122 success_food 0 spilled_food 0 distance 0.5778564392947485\n",
      "acc_reward:  -117.9697442717518 success_food 0 spilled_food 1 distance 0.4358198580977062\n",
      "acc_reward:  -129.51309192989277 success_food 0 spilled_food 0 distance 0.6087666609657338\n",
      "acc_reward:  -63.64980972522595 success_food 0 spilled_food 0 distance 0.23549113875762484\n",
      "acc_reward:  -134.57471157127466 success_food 0 spilled_food 0 distance 0.6973948209941222\n",
      "acc_reward:  -104.17341802311775 success_food 0 spilled_food 0 distance 0.3834184072260923\n",
      "acc_reward:  -88.10213530182654 success_food 0 spilled_food 0 distance 0.2880830629728304\n",
      "acc_reward:  -61.540837163764884 success_food 0 spilled_food 0 distance 0.13926880991867668\n",
      "acc_reward:  -43.932037828491715 success_food 0 spilled_food 1 distance 0.11584465060575756\n",
      "acc_reward:  -85.94479677238265 success_food 0 spilled_food 0 distance 0.3494769566165704\n",
      "acc_reward:  -95.21775217785354 success_food 0 spilled_food 0 distance 0.21820949777204873\n",
      "acc_reward:  -106.82202308189908 success_food 0 spilled_food 1 distance 0.4078060371245413\n",
      "acc_reward:  -33.19114592908016 success_food 0 spilled_food 0 distance 0.05822735251680144\n",
      "acc_reward:  129.84138468088938 success_food 8 spilled_food 0 distance 0.03981769813309866\n",
      "acc_reward:  -71.94184217674977 success_food 0 spilled_food 0 distance 0.24456685291900215\n",
      "acc_reward:  49.811909750263986 success_food 5 spilled_food 3 distance 0.041133125828589405\n",
      "acc_reward:  -67.94966654627413 success_food 0 spilled_food 0 distance 0.20099479498887687\n",
      "acc_reward:  -50.387987527246565 success_food 0 spilled_food 0 distance 0.11988086372604408\n",
      "acc_reward:  -53.32352401013843 success_food 0 spilled_food 0 distance 0.10267932618235057\n",
      "acc_reward:  117.7699448169767 success_food 8 spilled_food 0 distance 0.08132007682100209\n",
      "acc_reward:  121.73090100218161 success_food 8 spilled_food 0 distance 0.04482803986475858\n",
      "acc_reward:  127.67137262595875 success_food 8 spilled_food 0 distance 0.071692425359851\n",
      "acc_reward:  134.81759561409288 success_food 8 spilled_food 0 distance 0.04913870718700439\n",
      "acc_reward:  -52.797865858154964 success_food 0 spilled_food 2 distance 0.06299234936728122\n",
      "acc_reward:  -67.2468692845331 success_food 0 spilled_food 0 distance 0.16381990967587506\n",
      "acc_reward:  113.40110566067074 success_food 8 spilled_food 0 distance 0.05045863785750021\n",
      "acc_reward:  -72.95114461208584 success_food 0 spilled_food 4 distance 0.08599787900655709\n",
      "acc_reward:  120.80898149550427 success_food 8 spilled_food 0 distance 0.05924054208377912\n",
      "acc_reward:  -92.9725974548027 success_food 0 spilled_food 0 distance 0.35822210886406075\n",
      "acc_reward:  -90.2411921662538 success_food 0 spilled_food 0 distance 0.39325167989305404\n",
      "acc_reward:  -50.378625100258496 success_food 0 spilled_food 0 distance 0.12320381445657223\n",
      "acc_reward:  -73.4813317558316 success_food 0 spilled_food 0 distance 0.2027389455321357\n",
      "acc_reward:  -121.58736253893153 success_food 0 spilled_food 0 distance 0.5273883661033947\n",
      "acc_reward:  127.3099471155114 success_food 8 spilled_food 0 distance 0.06487185449801781\n",
      "acc_reward:  113.61413806072703 success_food 8 spilled_food 0 distance 0.0449995027414723\n",
      "acc_reward:  -30.30998351593643 success_food 0 spilled_food 0 distance 0.08684378119179005\n",
      "acc_reward:  102.82027823734374 success_food 7 spilled_food 1 distance 0.05139454766481705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_reward:  -30.106173177819002 success_food 0 spilled_food 0 distance 0.07770871880694077\n",
      "acc_reward:  -52.14077809039009 success_food 0 spilled_food 0 distance 0.19042628405205758\n",
      "acc_reward:  -80.77229455324849 success_food 0 spilled_food 0 distance 0.3723458014107908\n",
      "acc_reward:  131.6826515494688 success_food 8 spilled_food 0 distance 0.049365376692033267\n",
      "acc_reward:  -47.06602712870004 success_food 0 spilled_food 0 distance 0.1579187137874312\n",
      "acc_reward:  130.218207064498 success_food 8 spilled_food 0 distance 0.04487572810145913\n",
      "acc_reward:  -68.42599629427582 success_food 0 spilled_food 0 distance 0.31701590144537944\n",
      "acc_reward:  128.28690411242314 success_food 8 spilled_food 0 distance 0.05454098709773271\n",
      "acc_reward:  111.40302745697504 success_food 8 spilled_food 0 distance 0.033433087847291536\n",
      "acc_reward:  -66.50494792568165 success_food 0 spilled_food 0 distance 0.29532093051885\n",
      "acc_reward:  130.79449113303863 success_food 8 spilled_food 0 distance 0.04147331259137981\n",
      "acc_reward:  137.53881715751837 success_food 8 spilled_food 0 distance 0.037525178504101364\n",
      "acc_reward:  121.80596474054634 success_food 8 spilled_food 0 distance 0.037583406559104325\n",
      "acc_reward:  -35.58500227079462 success_food 0 spilled_food 0 distance 0.07885281447272112\n",
      "acc_reward:  -30.918044563989202 success_food 0 spilled_food 0 distance 0.08584080105792942\n",
      "acc_reward:  -64.04245492831434 success_food 0 spilled_food 0 distance 0.1985489239288599\n",
      "acc_reward:  -63.775590070113495 success_food 0 spilled_food 0 distance 0.2411373216308998\n",
      "acc_reward:  132.0091454339355 success_food 8 spilled_food 0 distance 0.05055550192780654\n",
      "acc_reward:  -34.3531083200268 success_food 0 spilled_food 0 distance 0.08894187408509441\n",
      "acc_reward:  -53.51676841111572 success_food 0 spilled_food 0 distance 0.05046655800094681\n",
      "acc_reward:  132.3759622629289 success_food 8 spilled_food 0 distance 0.040154095147821915\n",
      "acc_reward:  132.18032391111683 success_food 8 spilled_food 0 distance 0.039177221496082555\n",
      "acc_reward:  131.86106871083177 success_food 8 spilled_food 0 distance 0.042497302522041674\n",
      "acc_reward:  115.70745449003769 success_food 8 spilled_food 0 distance 0.06991586258790218\n",
      "acc_reward:  -74.42474387945379 success_food 0 spilled_food 0 distance 0.3294356940673228\n",
      "acc_reward:  -44.452091019159155 success_food 0 spilled_food 0 distance 0.06667865250138891\n",
      "acc_reward:  -48.35547265261372 success_food 0 spilled_food 0 distance 0.1352919770042829\n",
      "acc_reward:  -35.065422925932054 success_food 0 spilled_food 0 distance 0.08329864387844987\n",
      "acc_reward:  122.18676122628196 success_food 8 spilled_food 0 distance 0.05295363857845304\n",
      "acc_reward:  -31.722006887019234 success_food 0 spilled_food 0 distance 0.0863985757207704\n",
      "acc_reward:  126.13963880313017 success_food 8 spilled_food 0 distance 0.034997903349091974\n",
      "acc_reward:  129.00848773442013 success_food 8 spilled_food 0 distance 0.05024512952378198\n",
      "acc_reward:  125.71288884656624 success_food 8 spilled_food 0 distance 0.09220339695224149\n",
      "acc_reward:  129.30349530575558 success_food 8 spilled_food 0 distance 0.04772518100205307\n",
      "acc_reward:  129.7577438445698 success_food 8 spilled_food 0 distance 0.046378609598914114\n",
      "acc_reward:  -97.39261037252493 success_food 0 spilled_food 3 distance 0.39785878234675415\n",
      "acc_reward:  134.9732933352443 success_food 8 spilled_food 0 distance 0.04586629096728964\n",
      "acc_reward:  -76.22810885579902 success_food 0 spilled_food 0 distance 0.40803111063972397\n",
      "acc_reward:  121.64605251539 success_food 8 spilled_food 0 distance 0.04599861859137291\n",
      "acc_reward:  132.8016663320331 success_food 8 spilled_food 0 distance 0.037308189355448475\n",
      "acc_reward:  137.52236034591954 success_food 8 spilled_food 0 distance 0.06482797295831465\n",
      "acc_reward:  -40.8651571755045 success_food 0 spilled_food 0 distance 0.10128037632807677\n",
      "acc_reward:  -41.483701269753716 success_food 0 spilled_food 0 distance 0.08947558555824656\n",
      "acc_reward:  131.7740364947774 success_food 8 spilled_food 0 distance 0.03874193033721597\n",
      "acc_reward:  131.03998220511593 success_food 8 spilled_food 0 distance 0.043826702344433005\n",
      "acc_reward:  -52.76735985809963 success_food 0 spilled_food 0 distance 0.17438646895538773\n",
      "acc_reward:  120.91930672561432 success_food 8 spilled_food 0 distance 0.04888340019533416\n",
      "acc_reward:  -52.05299017615982 success_food 0 spilled_food 0 distance 0.06985351682588169\n",
      "acc_reward:  -41.18390616611933 success_food 0 spilled_food 0 distance 0.08576450487541332\n",
      "acc_reward:  130.82311485455594 success_food 8 spilled_food 0 distance 0.03602188019353082\n",
      "acc_reward:  -50.28378009878337 success_food 0 spilled_food 0 distance 0.0608074347974682\n",
      "acc_reward:  -41.016268064874346 success_food 0 spilled_food 0 distance 0.08219996351819538\n",
      "acc_reward:  119.86483819239496 success_food 8 spilled_food 0 distance 0.04029057863059263\n",
      "acc_reward:  132.45677242314304 success_food 8 spilled_food 0 distance 0.07197382137011892\n",
      "acc_reward:  133.69518764603953 success_food 8 spilled_food 0 distance 0.04907454557444911\n",
      "acc_reward:  134.13522962526818 success_food 8 spilled_food 0 distance 0.04330939923546858\n",
      "acc_reward:  132.05741455583552 success_food 8 spilled_food 0 distance 0.03685671111168844\n",
      "acc_reward:  -65.79697265841453 success_food 0 spilled_food 0 distance 0.26811752329730304\n",
      "acc_reward:  -56.96614294280914 success_food 0 spilled_food 0 distance 0.20751857787999942\n",
      "acc_reward:  -41.700483384097346 success_food 0 spilled_food 0 distance 0.17289803869985051\n",
      "acc_reward:  -41.26495571891005 success_food 0 spilled_food 0 distance 0.05535558227751638\n",
      "acc_reward:  133.2555651157758 success_food 8 spilled_food 0 distance 0.04129096213160894\n",
      "acc_reward:  -38.37173831718572 success_food 0 spilled_food 0 distance 0.06471530287153135\n",
      "acc_reward:  -41.1074528304002 success_food 0 spilled_food 0 distance 0.06762049282702441\n",
      "acc_reward:  -51.46942606399487 success_food 0 spilled_food 0 distance 0.13524469234537329\n",
      "acc_reward:  -52.836115985126625 success_food 0 spilled_food 0 distance 0.07841715786999728\n",
      "acc_reward:  -41.97101614565087 success_food 0 spilled_food 0 distance 0.11597650904749425\n",
      "acc_reward:  -62.46973872420648 success_food 0 spilled_food 0 distance 0.29281347113791917\n",
      "acc_reward:  -43.815830130898156 success_food 0 spilled_food 0 distance 0.08329750007396237\n",
      "acc_reward:  -52.92662983538417 success_food 0 spilled_food 0 distance 0.1138840625458415\n",
      "acc_reward:  -48.98132119556907 success_food 0 spilled_food 0 distance 0.11978478097062599\n",
      "acc_reward:  -38.941929557639405 success_food 0 spilled_food 0 distance 0.07311311384109362\n",
      "acc_reward:  132.91952058886716 success_food 8 spilled_food 0 distance 0.02862378082325633\n",
      "acc_reward:  -27.497479989754833 success_food 0 spilled_food 0 distance 0.06592216806655636\n",
      "acc_reward:  -37.72426298692237 success_food 0 spilled_food 0 distance 0.09500175371814841\n",
      "acc_reward:  129.44977950546968 success_food 8 spilled_food 0 distance 0.041650934910190576\n",
      "acc_reward:  -34.79215786095152 success_food 0 spilled_food 0 distance 0.0662615291623253\n",
      "acc_reward:  133.50208678194105 success_food 8 spilled_food 0 distance 0.04433994566359542\n",
      "acc_reward:  131.29082668189528 success_food 8 spilled_food 0 distance 0.04333570004691575\n",
      "acc_reward:  133.01317580741042 success_food 8 spilled_food 0 distance 0.04269906239598154\n",
      "acc_reward:  134.46866634117623 success_food 8 spilled_food 0 distance 0.04814468572258229\n",
      "acc_reward:  -42.58835484314721 success_food 0 spilled_food 0 distance 0.14877800355443174\n",
      "acc_reward:  -65.27787941063228 success_food 0 spilled_food 0 distance 0.3286872990488076\n",
      "acc_reward:  -36.065804202997754 success_food 0 spilled_food 0 distance 0.07378009287539725\n",
      "acc_reward:  -50.86520960388117 success_food 0 spilled_food 0 distance 0.09275088439121612\n",
      "acc_reward:  -37.56218520073419 success_food 0 spilled_food 0 distance 0.07593010797873749\n",
      "acc_reward:  -32.269190498955815 success_food 0 spilled_food 0 distance 0.08938618333967713\n",
      "acc_reward:  124.10941945809692 success_food 8 spilled_food 0 distance 0.043324956326546454\n",
      "acc_reward:  132.89867139419877 success_food 8 spilled_food 0 distance 0.05021948070352866\n",
      "acc_reward:  -39.383239747111105 success_food 0 spilled_food 0 distance 0.18401784980946476\n",
      "acc_reward:  125.35682194901646 success_food 8 spilled_food 0 distance 0.04834772070299217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_reward:  -40.16670408179553 success_food 0 spilled_food 0 distance 0.0602563701209409\n",
      "acc_reward:  -36.68225184670142 success_food 0 spilled_food 0 distance 0.05044265691009493\n",
      "acc_reward:  -47.4456540738401 success_food 0 spilled_food 0 distance 0.07516277586673975\n",
      "acc_reward:  -60.67167422772276 success_food 0 spilled_food 0 distance 0.20197077178521838\n",
      "acc_reward:  131.54974667129605 success_food 8 spilled_food 0 distance 0.04445050261786729\n",
      "acc_reward:  -42.412749402309394 success_food 0 spilled_food 0 distance 0.07517535486295322\n",
      "acc_reward:  -66.88831311776784 success_food 0 spilled_food 0 distance 0.2897474407489301\n",
      "acc_reward:  -40.540026299797354 success_food 0 spilled_food 0 distance 0.08761273556118682\n",
      "acc_reward:  -54.23688848163104 success_food 0 spilled_food 0 distance 0.1578133506853402\n",
      "acc_reward:  119.70445025958625 success_food 8 spilled_food 0 distance 0.047219905718006064\n",
      "acc_reward:  -46.362996411366204 success_food 0 spilled_food 0 distance 0.06930354133821397\n",
      "acc_reward:  -42.65774835925776 success_food 0 spilled_food 0 distance 0.13142733767620762\n",
      "acc_reward:  -42.705878230394326 success_food 0 spilled_food 0 distance 0.15178507732851027\n",
      "acc_reward:  -58.24753987009439 success_food 0 spilled_food 0 distance 0.19327510867141892\n",
      "acc_reward:  -28.782404197001803 success_food 0 spilled_food 0 distance 0.08572913254372759\n",
      "acc_reward:  134.82930663848424 success_food 8 spilled_food 0 distance 0.041845443230183466\n",
      "acc_reward:  -31.69232382448999 success_food 0 spilled_food 0 distance 0.07249653034584233\n",
      "acc_reward:  133.2709170936844 success_food 8 spilled_food 0 distance 0.04595477814131218\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\"\"\"testing the model with MPC while training \"\"\"\n",
    "test_episode = 200\n",
    "save_every = 10\n",
    "log = []\n",
    "for epi in range(test_episode):\n",
    "    acc_reward = 0\n",
    "    obs = env.reset()\n",
    "    O, A, R, acc_reward, done = [], [], [], 0, False\n",
    "    mpc_controller.reset()\n",
    "    while not done:\n",
    "        action = mpc_controller.act(model=model, state=obs)\n",
    "        obs_next, reward, done, info = env.step(action)\n",
    "#         print(obs_next)\n",
    "        A.append(action)\n",
    "        O.append(obs_next)\n",
    "        R.append(reward)\n",
    "        # append data but not training\n",
    "        model.data_process([0, obs, action, obs_next - obs])\n",
    "        obs = obs_next\n",
    "        acc_reward += reward\n",
    "#         print(obs[-1])\n",
    "    print('acc_reward: ', acc_reward, 'success_food',info['task_success'], 'spilled_food',info['spilled_food'], 'distance', np.linalg.norm(obs[6:9]))\n",
    "    model.fit()\n",
    "    if epi % save_every == 0:\n",
    "        torch.save(model.model.state_dict(), './log/ar_nn_ju_{}.pth'.format(epi))\n",
    "\n",
    "#     if done:\n",
    "#         samples = {\n",
    "#             \"obs\": np.array(O),\n",
    "#             \"actions\": np.array(A),\n",
    "#             \"rewards\": np.array(R), \n",
    "#             \"reward_sum\": acc_reward,\n",
    "#         }\n",
    "#         log.append(samples)\n",
    "#         if log_name is None:\n",
    "#             log_name = datetime.datetime.now()\n",
    "#         path = './misc/log/' + log_name.strftime(\"%d-%H-%M\") + '.npy'\n",
    "#         np.save(path, log, allow_pickle=True)\n",
    "#         dumb_reward_plot(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.model.state_dict(), 'ar_nn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
